"""
SEAL-LOC å®Œæ•´æµ‹è¯•ç³»ç»Ÿ

å®Œæ•´æµç¨‹æµ‹è¯•ï¼š
1. ä½¿ç”¨TAG-WMç”Ÿæˆç‰ˆæƒæ°´å°Wcop
2. ä½¿ç”¨åˆ›æ–°çš„è¯­ä¹‰å®šä½æ°´å°ç”ŸæˆWloc
3. ä½¿ç”¨åŸæœ‰çš„DMJSç”Ÿæˆåˆå§‹å™ªå£°ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾ç‰‡
4. é‡‡ç”¨åŸæœ‰çš„å™ªå£°é‡å»ºæ–¹æ¡ˆå¾—åˆ°ç‰ˆæƒæ°´å°å’Œå®šä½æ°´å°ï¼Œè®¡ç®—bitç²¾åº¦

å‚è€ƒTAG-WMåŸå§‹ä»£ç ï¼Œç›´æ¥å¤ç”¨æ‰©æ•£æ¨¡å‹åŠ è½½å’Œæç¤ºè¯å¤„ç†
"""

import torch
import numpy as np
import os
import sys
import hashlib
import argparse
import time
from PIL import Image
from typing import Tuple, List, Optional
import math
import zlib
import random

# è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨DVRD
os.environ['DISABLE_DVRD'] = '1'

# æ·»åŠ è·¯å¾„
sys.path.append('../applied_to_sd2')
sys.path.append('../baseline')

# å¯¼å…¥TAG-WMæ ¸å¿ƒç»„ä»¶
from watermark_embedder import WatermarkEmbedder

# å¯¼å…¥æ‰©æ•£æ¨¡å‹ç»„ä»¶
try:
    from inverse_stable_diffusion import InversableStableDiffusionPipeline
    from modified_stable_diffusion import ModifiedStableDiffusionPipeline
except ImportError:
    try:
        from diffusers import StableDiffusionPipeline as InversableStableDiffusionPipeline
        print("Warning: Using standard diffusers instead of modified versions")
    except ImportError:
        print("Error: Could not import diffusers. Please install with: pip install diffusers")
        raise

# å¯¼å…¥SEAL-LOCç»„ä»¶
try:
    from seal_loc_embedder import SEALLOCEmbedder
    from simhash_utils import simhash_single_patch
    from patch_utils import calculate_patch_l2, transform_img
except ImportError as e:
    print(f"Warning: Could not import SEAL-LOC components: {e}")
    print("Please make sure you are running from the watermarkLOC directory")
    raise

# å¯¼å…¥baselineå·¥å…·å‡½æ•°
sys.path.append('../baseline')
try:
    from caption_pairs import compute_simhash, generate_caption
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œæä¾›å¤‡ç”¨å®ç°
    print("Warning: Could not import from caption_pairs, using fallback implementations")
    
    def compute_simhash(embedding, num_patches, num_bits, seed):
        """å¤‡ç”¨çš„compute_simhashå®ç°"""
        import random
        import zlib
        import torch
        
        random.seed(seed)
        hash_keys = []
        
        for patch_index in range(num_patches):
            bits = [0] * num_bits
            for bit_index in range(num_bits):
                random_vector = torch.randn_like(embedding)
                bits[bit_index] = 1 if torch.dot(random_vector, embedding) > 0 else 0
                bits[bit_index] = (bits[bit_index] + bit_index + patch_index) % 256
            hash_keys.append(zlib.crc32(bytes(bits)) & 0xFFFFFFFF)
        
        return hash_keys
    
    def generate_caption(image, processor=None, model=None, device='cuda'):
        """å¤‡ç”¨çš„generate_captionå®ç°"""
        return "A generated image"  # ç®€å•çš„å¤‡ç”¨å®ç°


def create_baseline_simhash_function():
    """åˆ›å»ºä¸baselineå…¼å®¹çš„simhashå‡½æ•°"""
    def simhash(embedding, k, b, seed):
        """
        å…¼å®¹baselineçš„simhashå‡½æ•°
        å‚æ•°ï¼š
        - embedding: è¯­ä¹‰åµŒå…¥å‘é‡
        - k: patchæ•°é‡ (64)
        - b: simhashæ¯”ç‰¹æ•° (7)
        - seed: éšæœºç§å­
        """
        return compute_simhash(embedding, k, b, seed)
    
    return simhash


class CompleteSEALLOCTest:
    """å®Œæ•´çš„SEAL-LOCæµ‹è¯•ç³»ç»Ÿ"""
    
    def __init__(self, device='cuda', model_id='stabilityai/stable-diffusion-2-1-base'):
        self.device = device
        self.model_id = model_id
        
        # æœ¬åœ°æ¨¡å‹è·¯å¾„æ˜ å°„
        self.local_model_paths = {
            'stabilityai/stable-diffusion-2-1-base': '/home/wang003/.cache/modelscope/hub/models/AI-ModelScope/stable-diffusion-2-1-base',
            'laion/CLIP-ViT-g-14-laion2B-s12B-b42K': '/media/wang003/liyongqing/difusion/cache/models--laion--CLIP-ViT-g-14-laion2B-s12B-b42K/snapshots/4b0305adc6802b2632e11cbe6606a9bdd43d35c9',
            'Salesforce/blip2-flan-t5-xl': '/home/wang003/.cache/modelscope/hub/models/zimuwangnlp/flan-t5-xl',
            'kasraarabi/finetuned-caption-embedding': '/home/wang003/.cache/modelscope/hub/models/kasraarabi/finetuned-caption-embedding'
        }
        
        print(f"ğŸš€ åˆå§‹åŒ–SEAL-LOCå®Œæ•´æµ‹è¯•ç³»ç»Ÿ (è®¾å¤‡: {device})")
        print(f"ğŸ“ æ‰©æ•£æ¨¡å‹: {model_id}")
        
        # åˆå§‹åŒ–SEAL-LOCåµŒå…¥å™¨
        self.seal_loc_embedder = SEALLOCEmbedder(device=device)
        
        # åˆå§‹åŒ–TAG-WMæ°´å°åµŒå…¥å™¨ï¼ˆç”¨äºç‰ˆæƒæ°´å°ï¼‰
        self.tag_wm_embedder = WatermarkEmbedder(
            wm_len=256,
            center_interval_ratio=0.5,
            shuffle_random_seed=133563,
            encrypt_random_seed=133563,
            tlt_intervals_num=3,
            device=device
        )
        
        # æ‰©æ•£æ¨¡å‹ç®¡çº¿
        self.pipe = None
        
        # åˆ›å»ºbaselineå…¼å®¹çš„simhashå‡½æ•°
        self.simhash = create_baseline_simhash_function()
        
        print("âœ… SEAL-LOCæµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def load_diffusion_model(self):
        """åŠ è½½æ‰©æ•£æ¨¡å‹ï¼Œå¤ç”¨TAG-WMåŸå§‹ä»£ç é€»è¾‘"""
        print("ğŸ”„ åŠ è½½Stable Diffusion 2.1æ¨¡å‹...")
        
        # å°è¯•ä½¿ç”¨æœ¬åœ°è·¯å¾„
        model_path = self.local_model_paths.get(self.model_id, self.model_id)
        
        try:
            print(f"ğŸ“ å°è¯•ä»æœ¬åœ°è·¯å¾„åŠ è½½: {model_path}")
            # ä½¿ç”¨å¯åæ¼”çš„Stable Diffusionç®¡çº¿
            self.pipe = InversableStableDiffusionPipeline.from_pretrained(
                model_path,
                torch_dtype=torch.float16,
                local_files_only=True,  # å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
            )
            self.pipe.safety_checker = None  # ç¦ç”¨å®‰å…¨æ£€æŸ¥å™¨
            self.pipe = self.pipe.to(self.device)
            print("âœ… æ‰©æ•£æ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ”„ å°è¯•åœ¨çº¿åŠ è½½...")
            try:
                self.pipe = InversableStableDiffusionPipeline.from_pretrained(
                    self.model_id,
                    torch_dtype=torch.float16,
                    revision='fp16',
                )
                self.pipe.safety_checker = None
                self.pipe = self.pipe.to(self.device)
                print("âœ… åœ¨çº¿æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e2:
                print(f"âŒ åœ¨çº¿æ¨¡å‹åŠ è½½ä¹Ÿå¤±è´¥: {e2}")
                raise e2
    
    def generate_copyright_watermark(self, message: str = "SEAL-LOC-TEST") -> torch.Tensor:
        """ç”Ÿæˆç‰ˆæƒæ°´å°Wcopï¼Œä½¿ç”¨TAG-WMæ–¹æ¡ˆ"""
        print("ğŸ”’ ç”Ÿæˆç‰ˆæƒæ°´å° (Wcop)...")
        
        # å°†æ¶ˆæ¯è½¬æ¢ä¸ºäºŒè¿›åˆ¶
        message_bytes = message.encode('utf-8')
        message_bits = ''.join(format(byte, '08b') for byte in message_bytes)
        
        # æˆªæ–­æˆ–å¡«å……åˆ°256ä½
        if len(message_bits) > 256:
            message_bits = message_bits[:256]
        else:
            message_bits = message_bits.ljust(256, '0')
        
        # è½¬æ¢ä¸ºtensor
        wm_tensor = torch.tensor([int(bit) for bit in message_bits], 
                                dtype=torch.float32, device=self.device)
        
        print(f"âœ… ç‰ˆæƒæ°´å°ç”Ÿæˆå®Œæˆ (é•¿åº¦: {len(wm_tensor)})")
        return wm_tensor
    
    def generate_semantic_location_watermark(self, prompt: str, latent_size: Tuple[int, int, int]) -> Tuple[torch.Tensor, List[torch.Tensor]]:
        """ç”Ÿæˆè¯­ä¹‰å®šä½æ°´å°Wlocï¼Œä½¿ç”¨SEAL-LOCåˆ›æ–°æ–¹æ¡ˆ"""
        print("ğŸ¯ ç”Ÿæˆè¯­ä¹‰å®šä½æ°´å° (Wloc)...")
        
        try:
            # ä½¿ç”¨SEAL-LOCåµŒå…¥å™¨ç”Ÿæˆè¯­ä¹‰å®šä½æ°´å°
            # å…ˆç”Ÿæˆä»£ç†å›¾åƒ
            print("  ğŸ“¸ ç”Ÿæˆä»£ç†å›¾åƒ...")
            proxy_image = self.pipe(prompt).images[0]
            
            # æå–é€patchè¯­ä¹‰ç‰¹å¾
            print("  ğŸ§  æå–patchè¯­ä¹‰ç‰¹å¾...")
            semantic_vectors = self.seal_loc_embedder.extract_patch_semantics(
                proxy_image, latent_size
            )
            
            # ç”ŸæˆåŠ¨æ€è¯­ä¹‰å®šä½æ°´å°
            print("  ğŸ”— ç”ŸæˆåŠ¨æ€è¯­ä¹‰å®šä½æ°´å°...")
            w_loc_s = self.seal_loc_embedder.generate_dynamic_semantic_watermark(
                semantic_vectors, latent_size
            )
            
            print(f"âœ… è¯­ä¹‰å®šä½æ°´å°ç”Ÿæˆå®Œæˆ (å½¢çŠ¶: {w_loc_s.shape})")
            return w_loc_s, semantic_vectors
            
        except Exception as e:
            print(f"âŒ è¯­ä¹‰å®šä½æ°´å°ç”Ÿæˆå¤±è´¥: {e}")
            # å›é€€åˆ°æ¨¡æ‹Ÿæ–¹æ¡ˆ
            print("ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿè¯­ä¹‰å‘é‡...")
            return self.generate_simulated_location_watermark(latent_size)
    
    def generate_simulated_location_watermark(self, latent_size: Tuple[int, int, int]) -> Tuple[torch.Tensor, List[torch.Tensor]]:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„è¯­ä¹‰å®šä½æ°´å°ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        print("ğŸ² ç”Ÿæˆæ¨¡æ‹Ÿè¯­ä¹‰å®šä½æ°´å°...")
        
        # æ¨¡æ‹Ÿ64ä¸ªpatchçš„è¯­ä¹‰å‘é‡
        num_patches = 64
        semantic_dim = 768
        
        semantic_vectors = []
        for i in range(num_patches):
            # ç”Ÿæˆç¡®å®šæ€§çš„æ¨¡æ‹Ÿè¯­ä¹‰å‘é‡
            torch.manual_seed(42 + i)
            semantic_vector = torch.randn(semantic_dim, device=self.device)
            semantic_vector = semantic_vector / torch.norm(semantic_vector)  # å½’ä¸€åŒ–
            semantic_vectors.append(semantic_vector)
        
        # ç”Ÿæˆæ°´å°æ¯”ç‰¹
        total_bits = latent_size[0] * latent_size[1] * latent_size[2]
        w_loc_bits = []
        
        for i, semantic_vector in enumerate(semantic_vectors):
            # ä½¿ç”¨simhashç”Ÿæˆç¡®å®šæ€§ç§å­
            hash_seed = simhash_single_patch(semantic_vector, num_bits=7, seed=42 + i)
            
            # è®¡ç®—æ¯ä¸ªpatchéœ€è¦çš„æ¯”ç‰¹æ•°
            bits_per_patch = total_bits // num_patches
            
            # ç”Ÿæˆç¡®å®šæ€§æ°´å°æ¯”ç‰¹
            np.random.seed(hash_seed & 0xFFFFFFFF)
            patch_bits = np.random.randint(0, 2, size=bits_per_patch)
            w_loc_bits.extend(patch_bits)
        
        # è°ƒæ•´åˆ°ç²¾ç¡®çš„æ€»æ¯”ç‰¹æ•°
        if len(w_loc_bits) > total_bits:
            w_loc_bits = w_loc_bits[:total_bits]
        elif len(w_loc_bits) < total_bits:
            w_loc_bits.extend([0] * (total_bits - len(w_loc_bits)))
        
        # è½¬æ¢ä¸ºtensorå¹¶reshape
        w_loc_s = torch.tensor(w_loc_bits, dtype=torch.float32, device=self.device)
        w_loc_s = w_loc_s.reshape(latent_size)
        
        print(f"âœ… æ¨¡æ‹Ÿè¯­ä¹‰å®šä½æ°´å°ç”Ÿæˆå®Œæˆ (å½¢çŠ¶: {w_loc_s.shape})")
        return w_loc_s, semantic_vectors
    
    def generate_initial_noise_dmjs(self, w_cop: torch.Tensor, w_loc: torch.Tensor) -> torch.Tensor:
        """ä½¿ç”¨DMJSç”Ÿæˆåˆå§‹å™ªå£°ï¼Œå¤ç”¨TAG-WMæ–¹æ¡ˆ"""
        print("ğŸ² ä½¿ç”¨DMJSç”Ÿæˆåˆå§‹å™ªå£°...")
        
        try:
            # å°†tensorè½¬æ¢ä¸º1ç»´
            w_loc_flat = w_loc.flatten()
            total_len = len(w_loc_flat)
            
            # å°†ç‰ˆæƒæ°´å°é‡å¤æ‰©å±•åˆ°ä¸å®šä½æ°´å°ç›¸åŒçš„é•¿åº¦
            w_cop_expanded = w_cop.repeat((total_len + len(w_cop) - 1) // len(w_cop))[:total_len]
            
            print(f"  ç‰ˆæƒæ°´å°æ‰©å±•: {len(w_cop)} â†’ {len(w_cop_expanded)}")
            print(f"  å®šä½æ°´å°é•¿åº¦: {len(w_loc_flat)}")
            
            # ä½¿ç”¨TAG-WMçš„DMJSé‡‡æ ·
            sampled_noise_flat = self.tag_wm_embedder.denseWMandDenseFixedTLTtruncSampling(w_cop_expanded, w_loc_flat)
            
            # æ‰“ä¹±å™ªå£°ï¼ˆTAG-WMçš„æ ‡å‡†æµç¨‹ï¼‰
            sampled_noise_flat = self.tag_wm_embedder.shuffle(sampled_noise_flat)
            
            # é‡å¡‘ä¸ºlatentå½¢çŠ¶å¹¶æ·»åŠ batchç»´åº¦
            latent_noise = sampled_noise_flat.reshape(1, *w_loc.shape)
            
            print("âœ… ä½¿ç”¨TAG-WMçš„DMJSé‡‡æ ·æˆåŠŸ")
            
        except Exception as e:
            print(f"Warning: DMJS failed, using fallback: {e}")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šç®€å•çš„æ­£æ€åˆ†å¸ƒå™ªå£°
            latent_noise = torch.randn(1, *w_loc.shape, device=self.device, dtype=torch.float16)
        
        print(f"âœ… åˆå§‹å™ªå£°ç”Ÿæˆå®Œæˆ (å½¢çŠ¶: {latent_noise.shape})")
        return latent_noise
    
    def generate_watermarked_image(self, prompt: str, latent_noise: torch.Tensor) -> Image.Image:
        """ä½¿ç”¨æ°´å°åŒ–å™ªå£°ç”Ÿæˆå›¾åƒ"""
        print("ğŸ¨ ç”Ÿæˆæ°´å°åŒ–å›¾åƒ...")
        
        # ä½¿ç”¨æ°´å°åŒ–å™ªå£°ä½œä¸ºåˆå§‹latents
        image = self.pipe(prompt, latents=latent_noise).images[0]
        
        print("âœ… æ°´å°åŒ–å›¾åƒç”Ÿæˆå®Œæˆ")
        return image
    
    def reconstruct_watermarks(self, image: Image.Image, original_w_cop: torch.Tensor, 
                              original_w_loc: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, dict]:
        """é‡å»ºæ°´å°å¹¶è®¡ç®—ç²¾åº¦"""
        print("ğŸ” é‡å»ºæ°´å°...")
        
        # å°†å›¾åƒè½¬æ¢ä¸ºtensor
        image_tensor = transform_img(image).unsqueeze(0).to(self.device)
        image_tensor = image_tensor.to(dtype=self.pipe.vae.dtype)
        
        # è·å–å›¾åƒçš„latentè¡¨ç¤º
        image_latents = self.pipe.get_image_latents(image_tensor, sample=False)
        
        # DDIMåè½¬å¾—åˆ°åˆå§‹å™ªå£°
        print("  ğŸ”„ æ‰§è¡ŒDDIMåè½¬...")
        reconstructed_noise = self.pipe.forward_diffusion(
            latents=image_latents,
            text_embeddings=self.pipe.get_text_embedding(''),
            guidance_scale=1,
            num_inference_steps=50,
        )
        
        # ä½¿ç”¨TAG-WMé‡å»ºæ°´å°
        print("  ğŸ“Š é‡å»ºç‰ˆæƒæ°´å°å’Œå®šä½æ°´å°...")
        reconstructed_w_cop, reconstructed_w_loc = self.tag_wm_embedder.extract_watermark(
            reconstructed_noise
        )
        
        # è®¡ç®—ç²¾åº¦
        metrics = self.calculate_bit_accuracy(
            original_w_cop, original_w_loc,
            reconstructed_w_cop, reconstructed_w_loc
        )
        
        print("âœ… æ°´å°é‡å»ºå®Œæˆ")
        return reconstructed_w_cop, reconstructed_w_loc, metrics
    
    def calculate_bit_accuracy(self, orig_w_cop: torch.Tensor, orig_w_loc: torch.Tensor,
                              recon_w_cop: torch.Tensor, recon_w_loc: torch.Tensor) -> dict:
        """è®¡ç®—æ°´å°æ¯”ç‰¹ç²¾åº¦"""
        print("ğŸ“ è®¡ç®—æ¯”ç‰¹ç²¾åº¦...")
        
        # ç‰ˆæƒæ°´å°ç²¾åº¦
        cop_accuracy = (orig_w_cop == recon_w_cop).float().mean().item()
        
        # å®šä½æ°´å°ç²¾åº¦
        loc_accuracy = (orig_w_loc == recon_w_loc).float().mean().item()
        
        # è®¡ç®—L2è·ç¦»ï¼ˆç”¨äºSEALæ–¹æ¡ˆè¯„ä¼°ï¼‰
        l2_distance = calculate_patch_l2(
            orig_w_loc.unsqueeze(0), 
            recon_w_loc.unsqueeze(0), 
            k=64
        )
        
        metrics = {
            'copyright_accuracy': cop_accuracy,
            'location_accuracy': loc_accuracy,
            'l2_distance': l2_distance,
            'total_bits_cop': len(orig_w_cop),
            'total_bits_loc': orig_w_loc.numel(),
            'correct_bits_cop': int((orig_w_cop == recon_w_cop).sum()),
            'correct_bits_loc': int((orig_w_loc == recon_w_loc).sum())
        }
        
        print(f"ğŸ“Š ç‰ˆæƒæ°´å°ç²¾åº¦: {cop_accuracy:.4f}")
        print(f"ğŸ“Š å®šä½æ°´å°ç²¾åº¦: {loc_accuracy:.4f}")
        print(f"ğŸ“Š L2è·ç¦»: {l2_distance:.4f}")
        
        return metrics
    
    def run_complete_test(self, prompt: str = "A beautiful landscape with mountains and trees", 
                         output_dir: str = "output/complete_test") -> dict:
        """è¿è¡Œå®Œæ•´æµ‹è¯•æµç¨‹"""
        print("ğŸš€ å¼€å§‹SEAL-LOCå®Œæ•´æµ‹è¯•æµç¨‹")
        print(f"ğŸ“ æµ‹è¯•æç¤ºè¯: {prompt}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        start_time = time.time()
        
        try:
            # 1. åŠ è½½æ‰©æ•£æ¨¡å‹
            if self.pipe is None:
                self.load_diffusion_model()
            
            # 2. ç”Ÿæˆç‰ˆæƒæ°´å°
            w_cop = self.generate_copyright_watermark()
            
            # 3. ç”Ÿæˆè¯­ä¹‰å®šä½æ°´å°
            latent_size = (4, 64, 64)
            w_loc, semantic_vectors = self.generate_semantic_location_watermark(prompt, latent_size)
            
            # 4. ä½¿ç”¨DMJSç”Ÿæˆåˆå§‹å™ªå£°
            latent_noise = self.generate_initial_noise_dmjs(w_cop, w_loc)
            
            # 5. ç”Ÿæˆæ°´å°åŒ–å›¾åƒ
            watermarked_image = self.generate_watermarked_image(prompt, latent_noise)
            
            # 6. é‡å»ºæ°´å°å¹¶è®¡ç®—ç²¾åº¦
            recon_w_cop, recon_w_loc, metrics = self.reconstruct_watermarks(
                watermarked_image, w_cop, w_loc
            )
            
            # 7. ä¿å­˜ç»“æœ
            self.save_test_results(
                output_dir, prompt, watermarked_image, 
                w_cop, w_loc, recon_w_cop, recon_w_loc, 
                semantic_vectors, metrics
            )
            
            end_time = time.time()
            total_time = end_time - start_time
            
            print(f"âœ… å®Œæ•´æµ‹è¯•æµç¨‹å®Œæˆï¼è€—æ—¶: {total_time:.2f}ç§’")
            
            # æ·»åŠ æ—¶é—´ä¿¡æ¯åˆ°metrics
            metrics['total_time'] = total_time
            
            return metrics
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•æµç¨‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise e
    
    def save_test_results(self, output_dir: str, prompt: str, image: Image.Image,
                         w_cop: torch.Tensor, w_loc: torch.Tensor,
                         recon_w_cop: torch.Tensor, recon_w_loc: torch.Tensor,
                         semantic_vectors: List[torch.Tensor], metrics: dict):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        print("ğŸ’¾ ä¿å­˜æµ‹è¯•ç»“æœ...")
        
        # ä¿å­˜å›¾åƒ
        image_path = os.path.join(output_dir, "watermarked_image.png")
        image.save(image_path)
        
        # ä¿å­˜æ°´å°æ•°æ®
        watermark_data = {
            'prompt': prompt,
            'original_w_cop': w_cop.cpu().numpy(),
            'original_w_loc': w_loc.cpu().numpy(),
            'reconstructed_w_cop': recon_w_cop.cpu().numpy(),
            'reconstructed_w_loc': recon_w_loc.cpu().numpy(),
            'metrics': metrics
        }
        
        watermark_path = os.path.join(output_dir, "watermark_data.npz")
        np.savez(watermark_path, **watermark_data)
        
        # ä¿å­˜è¯­ä¹‰å‘é‡
        semantic_data = {f'semantic_vector_{i}': vec.cpu().numpy() 
                        for i, vec in enumerate(semantic_vectors)}
        semantic_path = os.path.join(output_dir, "semantic_vectors.npz")
        np.savez(semantic_path, **semantic_data)
        
        # ä¿å­˜metricsåˆ°æ–‡æœ¬æ–‡ä»¶
        metrics_path = os.path.join(output_dir, "metrics.txt")
        with open(metrics_path, 'w') as f:
            f.write(f"SEAL-LOC Complete Test Results\n")
            f.write(f"================================\n")
            f.write(f"Prompt: {prompt}\n")
            f.write(f"Copyright Watermark Accuracy: {metrics['copyright_accuracy']:.4f}\n")
            f.write(f"Location Watermark Accuracy: {metrics['location_accuracy']:.4f}\n")
            f.write(f"L2 Distance: {metrics['l2_distance']:.4f}\n")
            f.write(f"Total Time: {metrics.get('total_time', 0):.2f}s\n")
            f.write(f"Correct Copyright Bits: {metrics['correct_bits_cop']}/{metrics['total_bits_cop']}\n")
            f.write(f"Correct Location Bits: {metrics['correct_bits_loc']}/{metrics['total_bits_loc']}\n")
        
        print(f"âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")


def main():
    parser = argparse.ArgumentParser(description='SEAL-LOC Complete Test')
    parser.add_argument('--prompt', type=str, 
                       default="A beautiful landscape with mountains and trees",
                       help='æµ‹è¯•æç¤ºè¯')
    parser.add_argument('--device', type=str, default='cuda', 
                       help='è®¾å¤‡ (cuda/cpu)')
    parser.add_argument('--model_id', type=str, 
                       default='stabilityai/stable-diffusion-2-1-base',
                       help='æ‰©æ•£æ¨¡å‹ID')
    parser.add_argument('--output_dir', type=str, 
                       default='output/complete_test',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--num_tests', type=int, default=1,
                       help='æµ‹è¯•æ¬¡æ•°')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æµ‹è¯•ç³»ç»Ÿ
    tester = CompleteSEALLOCTest(device=args.device, model_id=args.model_id)
    
    # è¿è¡Œæµ‹è¯•
    all_metrics = []
    
    for i in range(args.num_tests):
        print(f"\nğŸ”„ è¿è¡Œç¬¬ {i+1}/{args.num_tests} æ¬¡æµ‹è¯•")
        
        test_output_dir = os.path.join(args.output_dir, f"test_{i+1}")
        
        try:
            metrics = tester.run_complete_test(
                prompt=args.prompt,
                output_dir=test_output_dir
            )
            all_metrics.append(metrics)
            
        except Exception as e:
            print(f"âŒ ç¬¬ {i+1} æ¬¡æµ‹è¯•å¤±è´¥: {e}")
            continue
    
    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    if all_metrics:
        avg_metrics = {
            'avg_copyright_accuracy': np.mean([m['copyright_accuracy'] for m in all_metrics]),
            'avg_location_accuracy': np.mean([m['location_accuracy'] for m in all_metrics]),
            'avg_l2_distance': np.mean([m['l2_distance'] for m in all_metrics]),
            'avg_total_time': np.mean([m.get('total_time', 0) for m in all_metrics])
        }
        
        print(f"\nğŸ“Š å¹³å‡æµ‹è¯•ç»“æœ ({len(all_metrics)} æ¬¡æµ‹è¯•):")
        print(f"å¹³å‡ç‰ˆæƒæ°´å°ç²¾åº¦: {avg_metrics['avg_copyright_accuracy']:.4f}")
        print(f"å¹³å‡å®šä½æ°´å°ç²¾åº¦: {avg_metrics['avg_location_accuracy']:.4f}")
        print(f"å¹³å‡L2è·ç¦»: {avg_metrics['avg_l2_distance']:.4f}")
        print(f"å¹³å‡è€—æ—¶: {avg_metrics['avg_total_time']:.2f}ç§’")
        
        # ä¿å­˜å¹³å‡ç»“æœ
        summary_path = os.path.join(args.output_dir, "summary.txt")
        with open(summary_path, 'w') as f:
            f.write(f"SEAL-LOC Complete Test Summary\n")
            f.write(f"==============================\n")
            f.write(f"Number of tests: {len(all_metrics)}\n")
            f.write(f"Average Copyright Accuracy: {avg_metrics['avg_copyright_accuracy']:.4f}\n")
            f.write(f"Average Location Accuracy: {avg_metrics['avg_location_accuracy']:.4f}\n")
            f.write(f"Average L2 Distance: {avg_metrics['avg_l2_distance']:.4f}\n")
            f.write(f"Average Time: {avg_metrics['avg_total_time']:.2f}s\n")
    
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main() 