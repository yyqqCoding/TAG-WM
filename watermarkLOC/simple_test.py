"""
SEAL-LOC ç®€åŒ–æµ‹è¯•ç³»ç»Ÿ

é¿å…å¤æ‚ä¾èµ–ï¼Œæä¾›åŸºæœ¬çš„åŠŸèƒ½æµ‹è¯•
"""

import torch
import numpy as np
import os
import sys
import hashlib
import argparse
import time
from PIL import Image
from typing import Tuple, List
import math
import zlib
import random

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['DISABLE_DVRD'] = '1'

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, os.path.join(parent_dir, 'applied_to_sd2'))
sys.path.insert(0, os.path.join(parent_dir, 'baseline'))

def safe_import_diffusers():
    """å®‰å…¨å¯¼å…¥æ‰©æ•£æ¨¡å‹"""
    try:
        from diffusers import StableDiffusionPipeline, DDIMScheduler
        return StableDiffusionPipeline, DDIMScheduler
    except ImportError:
        print("Error: diffusers not installed. Please install with: pip install diffusers")
        return None, None

def safe_import_tagwm():
    """å®‰å…¨å¯¼å…¥TAG-WMç»„ä»¶"""
    try:
        from watermark_embedder import WatermarkEmbedder
        return WatermarkEmbedder
    except ImportError as e:
        print(f"Warning: Could not import TAG-WM components: {e}")
        return None

def compute_simhash_fallback(embedding, num_patches, num_bits, seed):
    """æ”¹è¿›çš„SimHashå®ç°ï¼ŒåŸºäºè¯­ä¹‰å‘é‡å†…å®¹"""
    # ä½¿ç”¨è¯­ä¹‰å‘é‡çš„å†…å®¹ä½œä¸ºåŸºç¡€ï¼Œè€Œä¸æ˜¯å¤–éƒ¨éšæœºç§å­
    hash_keys = []
    
    for patch_index in range(num_patches):
        # ä¸ºæ¯ä¸ªpatchåˆ›å»ºç‹¬ç‰¹çš„æŠ•å½±åŸºç¡€
        patch_seed = hash(tuple(embedding.cpu().numpy())) + patch_index
        torch.manual_seed(patch_seed & 0x7FFFFFFF)  # ç¡®ä¿æ­£æ•°
        
        bits = [0] * num_bits
        for bit_index in range(num_bits):
            # ç”Ÿæˆå›ºå®šçš„éšæœºæŠ•å½±å‘é‡
            random_vector = torch.randn_like(embedding)
            # SimHashæ ¸å¿ƒï¼šè¯­ä¹‰å‘é‡ä¸éšæœºå‘é‡çš„ç‚¹ç§¯ç¬¦å·
            bits[bit_index] = 1 if torch.dot(random_vector, embedding) > 0 else 0
        
        # å°†æ¯”ç‰¹åºåˆ—è½¬æ¢ä¸ºå“ˆå¸Œå€¼
        hash_keys.append(zlib.crc32(bytes(bits)) & 0xFFFFFFFF)
    
    return hash_keys

def transform_img_fallback(image, target_size=512):
    """å¤‡ç”¨çš„å›¾åƒå˜æ¢å®ç°"""
    from torchvision import transforms
    
    tform = transforms.Compose([
        transforms.Resize(target_size),
        transforms.CenterCrop(target_size),
        transforms.ToTensor(),
    ])
    image = tform(image)
    return 2.0 * image - 1.0

def calculate_patch_l2_fallback(noise1, noise2, k=64):
    """å¤‡ç”¨çš„patch L2è·ç¦»è®¡ç®—"""
    # ç®€åŒ–å®ç°ï¼Œç¡®ä¿è¾“å…¥ä¸ºfloatç±»å‹
    noise1_float = noise1.float() if noise1.dtype != torch.float32 else noise1
    noise2_float = noise2.float() if noise2.dtype != torch.float32 else noise2
    diff = noise1_float - noise2_float
    l2_dist = torch.norm(diff, p=2).item()
    return l2_dist

class SimpleSEALLOCTest:
    """ç®€åŒ–çš„SEAL-LOCæµ‹è¯•ç³»ç»Ÿ"""
    
    def __init__(self, device='cuda', model_id='stabilityai/stable-diffusion-2-1-base'):
        self.device = device
        self.model_id = model_id
        
        # æœ¬åœ°æ¨¡å‹è·¯å¾„æ˜ å°„
        self.local_model_paths = {
            'stabilityai/stable-diffusion-2-1-base': '/home/wang003/.cache/modelscope/hub/models/AI-ModelScope/stable-diffusion-2-1-base',
            'laion/CLIP-ViT-g-14-laion2B-s12B-b42K': '/media/wang003/liyongqing/difusion/cache/models--laion--CLIP-ViT-g-14-laion2B-s12B-b42K/snapshots/4b0305adc6802b2632e11cbe6606a9bdd43d35c9',
            'Salesforce/blip2-flan-t5-xl': '/home/wang003/.cache/modelscope/hub/models/zimuwangnlp/flan-t5-xl',
            'kasraarabi/finetuned-caption-embedding': '/home/wang003/.cache/modelscope/hub/models/kasraarabi/finetuned-caption-embedding'
        }
        
        print(f"ğŸš€ åˆå§‹åŒ–ç®€åŒ–SEAL-LOCæµ‹è¯•ç³»ç»Ÿ (è®¾å¤‡: {device})")
        
        # å¯¼å…¥ç»„ä»¶
        StableDiffusionPipeline, DDIMScheduler = safe_import_diffusers()
        WatermarkEmbedder = safe_import_tagwm()
        
        if StableDiffusionPipeline is None:
            raise ImportError("Cannot import diffusers")
        
        self.StableDiffusionPipeline = StableDiffusionPipeline
        self.DDIMScheduler = DDIMScheduler
        
        # åˆå§‹åŒ–TAG-WMåµŒå…¥å™¨
        if WatermarkEmbedder is not None:
            self.tag_wm_embedder = WatermarkEmbedder(
                wm_len=256,
                center_interval_ratio=0.5,
                shuffle_random_seed=133563,
                encrypt_random_seed=133563,
                tlt_intervals_num=3,
                device=device
            )
        else:
            self.tag_wm_embedder = None
        
        self.pipe = None
        
        print("âœ… ç®€åŒ–æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def load_diffusion_model(self):
        """åŠ è½½æ‰©æ•£æ¨¡å‹"""
        print("ğŸ”„ åŠ è½½Stable Diffusionæ¨¡å‹...")
        
        # å°è¯•ä½¿ç”¨æœ¬åœ°è·¯å¾„
        model_path = self.local_model_paths.get(self.model_id, self.model_id)
        
        try:
            print(f"ğŸ“ å°è¯•ä»æœ¬åœ°è·¯å¾„åŠ è½½: {model_path}")
            self.pipe = self.StableDiffusionPipeline.from_pretrained(
                model_path,
                torch_dtype=torch.float16,
                local_files_only=True,  # å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
            )
            self.pipe = self.pipe.to(self.device)
            print("âœ… æ‰©æ•£æ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ”„ å°è¯•åœ¨çº¿åŠ è½½...")
            try:
                self.pipe = self.StableDiffusionPipeline.from_pretrained(
                    self.model_id,
                    torch_dtype=torch.float16,
                    revision='fp16',
                )
                self.pipe = self.pipe.to(self.device)
                print("âœ… åœ¨çº¿æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e2:
                print(f"âŒ åœ¨çº¿æ¨¡å‹åŠ è½½ä¹Ÿå¤±è´¥: {e2}")
                raise e2
    
    def generate_copyright_watermark(self, message: str = "SEAL-LOC-TEST") -> torch.Tensor:
        """ç”Ÿæˆç‰ˆæƒæ°´å°"""
        print("ğŸ”’ ç”Ÿæˆç‰ˆæƒæ°´å°...")
        
        # å°†æ¶ˆæ¯è½¬æ¢ä¸ºäºŒè¿›åˆ¶
        message_bytes = message.encode('utf-8')
        message_bits = ''.join(format(byte, '08b') for byte in message_bytes)
        
        # æˆªæ–­æˆ–å¡«å……åˆ°256ä½
        if len(message_bits) > 256:
            message_bits = message_bits[:256]
        else:
            message_bits = message_bits.ljust(256, '0')
        
        wm_tensor = torch.tensor([int(bit) for bit in message_bits], 
                                dtype=torch.int32, device=self.device)
        
        print(f"âœ… ç‰ˆæƒæ°´å°ç”Ÿæˆå®Œæˆ (é•¿åº¦: {len(wm_tensor)})")
        return wm_tensor
    
    def generate_semantic_location_watermark(self, latent_size: Tuple[int, int, int], prompt: str = None) -> torch.Tensor:
        """
        ç”ŸæˆXORåŸºç¡€æ¨¡å¼çš„è¯­ä¹‰æ„ŸçŸ¥å®šä½æ°´å° - SEAL-LOCä¼˜åŒ–ç®—æ³•
        
        æµç¨‹ï¼š
        1. ç”Ÿæˆç¡®å®šæ€§åŸºç¡€æ¨¡å¼ P_base (å®Œç¾æ£‹ç›˜æ ¼)
        2. ç”Ÿæˆè¯­ä¹‰å¯†é’¥ K_sem (åŸºäºpromptçš„patchçº§è¯­ä¹‰)
        3. XORæ··åˆç”Ÿæˆæœ€ç»ˆå®šä½æ°´å° W_loc_final
        4. æœ€ç»ˆåˆ†å¸ƒæ ¡æ­£ç¡®ä¿ä¸¥æ ¼0.5åˆ†å¸ƒ
        
        ä¼˜åŠ¿ï¼š
        - å®Œç¾çš„ä¼¯åŠªåˆ©(0.5)åˆ†å¸ƒï¼šç»§æ‰¿TAG-WMçš„ç»Ÿè®¡ç‰¹æ€§
        - é«˜é¢‘æ•æ„Ÿç»“æ„ï¼šä¿æŒå¯¹ç¯¡æ”¹çš„æœ€å¤§æ•æ„Ÿåº¦
        - è¯­ä¹‰ç»‘å®šï¼šæ¯ä¸ªpatchä¸å†…å®¹å¯†ç å­¦çº§åˆ«ç»‘å®š
        """
        print("ğŸ¯ ç”ŸæˆXORåŸºç¡€æ¨¡å¼çš„SEAL-LOCè¯­ä¹‰å®šä½æ°´å°...")
        
        total_bits = latent_size[0] * latent_size[1] * latent_size[2]  # 4*64*64 = 16384
        
        # === æ­¥éª¤1ï¼šç”Ÿæˆç¡®å®šæ€§çš„åŸºç¡€æ¨¡å¼ P_base ===
        print("  ğŸ“ æ­¥éª¤1ï¼šç”ŸæˆåŸºç¡€æ¨¡å¼ (å®Œç¾æ£‹ç›˜æ ¼)")
        P_base = self._generate_perfect_base_pattern(total_bits)
        
        # === æ­¥éª¤2ï¼šç”Ÿæˆå†…å®¹ç›¸å…³çš„è¯­ä¹‰å¯†é’¥ K_sem ===
        print("  ğŸ”‘ æ­¥éª¤2ï¼šç”Ÿæˆè¯­ä¹‰å¯†é’¥")
        K_sem = self._generate_enhanced_semantic_key(latent_size, prompt)
        
        # === æ­¥éª¤3ï¼šXORæ··åˆç”Ÿæˆæœ€ç»ˆå®šä½æ°´å° ===
        print("  ğŸ”€ æ­¥éª¤3ï¼šXORæ··åˆç”Ÿæˆæœ€ç»ˆå®šä½æ°´å°")
        W_loc_final = P_base ^ K_sem
        
        # === æ­¥éª¤4ï¼šæœ€ç»ˆåˆ†å¸ƒæ ¡æ­£ï¼ˆå…³é”®ä¿®å¤ï¼‰===
        print("  ğŸ”§ æ­¥éª¤4ï¼šæœ€ç»ˆåˆ†å¸ƒæ ¡æ­£")
        W_loc_final = self._apply_final_distribution_correction(W_loc_final, prompt)
        
        # è½¬æ¢ä¸ºtorch tensorå¹¶reshape
        w_loc_tensor = torch.tensor(W_loc_final, dtype=torch.int32, device=self.device)
        w_loc_tensor = w_loc_tensor.reshape(latent_size)
        
        # éªŒè¯ç»Ÿè®¡ç‰¹æ€§
        ones_ratio = (W_loc_final == 1).sum() / len(W_loc_final)
        print(f"âœ… XORè¯­ä¹‰å®šä½æ°´å°ç”Ÿæˆå®Œæˆ")
        print(f"  ğŸ“Š åŸºç¡€æ¨¡å¼1çš„æ¯”ä¾‹: {(P_base == 1).sum() / len(P_base):.6f}")
        print(f"  ğŸ“Š è¯­ä¹‰å¯†é’¥1çš„æ¯”ä¾‹: {(K_sem == 1).sum() / len(K_sem):.6f}")
        print(f"  ğŸ“Š æœ€ç»ˆæ°´å°1çš„æ¯”ä¾‹: {ones_ratio:.6f} (å®Œç¾ç›®æ ‡: 0.500000)")
        print(f"  ğŸ¯ å®Œç¾ç»Ÿè®¡ç‰¹æ€§ + è¯­ä¹‰ç»‘å®š = æœ€ä¼˜SEAL-LOCå®šä½æ°´å°")
        
        return w_loc_tensor
    
    def _generate_perfect_base_pattern(self, total_bits: int) -> np.ndarray:
        """
        ç”Ÿæˆå®Œç¾çš„åŸºç¡€æ¨¡å¼ P_base
        
        å®Œå…¨å¤ç°TAG-WMçš„å¥‡å¶æ¨¡å¼ï¼Œç¡®ä¿ï¼š
        - ä¸¥æ ¼äº¤æ›¿çš„0-1-0-1-0-1...æ¨¡å¼  
        - å®Œç¾çš„ä¼¯åŠªåˆ©(0.5)åˆ†å¸ƒ
        - é«˜é¢‘æ£‹ç›˜æ ¼ç»“æ„ï¼Œå¯¹ç¯¡æ”¹æœ€æ•æ„Ÿ
        - å®Œå…¨ç¡®å®šæ€§ï¼Œä¸ä¾èµ–å›¾åƒå†…å®¹
        """
        # å®Œå…¨å¤ç°TAG-WM: np.arange(args.latent_len) % 2
        P_base = np.arange(total_bits) % 2
        
        # éªŒè¯å®Œç¾åˆ†å¸ƒç‰¹æ€§
        ones_count = (P_base == 1).sum()
        zeros_count = (P_base == 0).sum()
        
        print(f"    ğŸ“ TAG-WMå…¼å®¹åŸºç¡€æ¨¡å¼: {total_bits}ä½")
        print(f"    ğŸ“Š 0çš„æ•°é‡: {zeros_count}, 1çš„æ•°é‡: {ones_count}")
        print(f"    ğŸ“Š å®Œç¾æ¯”ä¾‹: {ones_count / total_bits:.6f}")
        print(f"    ğŸ¯ é«˜é¢‘ç»“æ„: 0-1-0-1-0-1... (å¯¹ç¯¡æ”¹æœ€æ•æ„Ÿ)")
        
        return P_base.astype(np.int32)

    def _generate_enhanced_semantic_key(self, latent_size: Tuple[int, int, int], prompt: str = None) -> np.ndarray:
        """
        ç”Ÿæˆå¢å¼ºçš„è¯­ä¹‰å¯†é’¥ K_sem
        
        åŸºäºpatchçº§è¯­ä¹‰å‘é‡ç”Ÿæˆä¸å†…å®¹ç»‘å®šçš„é«˜è´¨é‡ä¼ªéšæœºå¯†é’¥
        **æ–°å¢åˆ†å¸ƒæ ¡æ­£æœºåˆ¶ï¼Œç¡®ä¿ä¸¥æ ¼0.5åˆ†å¸ƒ**
        """
        total_bits = latent_size[0] * latent_size[1] * latent_size[2]
        
        # 8x8 = 64ä¸ªpatchçš„è¯­ä¹‰å¤„ç†
        patch_grid_size = 8
        num_patches = patch_grid_size * patch_grid_size
        bits_per_patch = total_bits // num_patches  # 256ä½/patch
        
        # åŸºäºpromptç”Ÿæˆç¡®å®šæ€§å…¨å±€ç§å­
        if prompt:
            prompt_hash = hash(prompt.lower().strip())
            global_seed = prompt_hash & 0x7FFFFFFF
            print(f"    ğŸ”‘ å…¨å±€ç§å­: '{prompt}' â†’ {global_seed}")
        else:
            global_seed = 42
            print(f"    ğŸ”‘ é»˜è®¤å…¨å±€ç§å­: {global_seed}")
        
        # ç”Ÿæˆæ¯ä¸ªpatchçš„è¯­ä¹‰å¯†é’¥
        K_sem = np.zeros(total_bits, dtype=np.int32)
        
        print(f"    ğŸ”‘ è¯­ä¹‰å¯†é’¥ç”Ÿæˆ: {num_patches}ä¸ªpatch, æ¯ä¸ª{bits_per_patch}ä½")
        
        for patch_idx in range(num_patches):
            # ä¸ºæ¯ä¸ªpatchç”Ÿæˆç‹¬ç‰¹çš„è¯­ä¹‰è¡¨ç¤º
            patch_seed = self._compute_patch_semantic_seed(prompt, patch_idx, global_seed)
            
            # åŸºäºè¯­ä¹‰ç§å­ç”Ÿæˆè¯¥patchçš„å¯†é’¥æ¯”ç‰¹
            patch_key_bits = self._generate_patch_key_bits(patch_seed, bits_per_patch)
            
            # å¡«å…¥å¯¹åº”ä½ç½®
            start_idx = patch_idx * bits_per_patch
            end_idx = start_idx + bits_per_patch
            K_sem[start_idx:end_idx] = patch_key_bits
        
        # å¤„ç†ä½™æ•°ä½
        remaining_bits = total_bits % num_patches
        if remaining_bits > 0:
            last_seed = self._compute_patch_semantic_seed(prompt, num_patches, global_seed)
            remaining_bits_data = self._generate_patch_key_bits(last_seed, remaining_bits)
            K_sem[-remaining_bits:] = remaining_bits_data
        
        # â­ æ–°å¢ï¼šåˆ†å¸ƒæ ¡æ­£æœºåˆ¶ â­
        K_sem = self._apply_distribution_correction(K_sem, prompt, global_seed)
        
        # éªŒè¯ä¼ªéšæœºæ€§
        ones_ratio = (K_sem == 1).sum() / total_bits
        print(f"    ğŸ“Š è¯­ä¹‰å¯†é’¥ç»Ÿè®¡: 1çš„æ¯”ä¾‹ {ones_ratio:.6f} (æ ¡æ­£å)")
        print(f"    ğŸ” è¯­ä¹‰ç»‘å®š: promptå†…å®¹ â†’ patchçº§ç§å­ â†’ ç¡®å®šæ€§å¯†é’¥")
        
        return K_sem
    
    def _apply_distribution_correction(self, K_sem: np.ndarray, prompt: str, global_seed: int) -> np.ndarray:
        """
        åº”ç”¨åˆ†å¸ƒæ ¡æ­£æœºåˆ¶ï¼Œç¡®ä¿K_semä¸¥æ ¼æ»¡è¶³0.5åˆ†å¸ƒ
        
        ç­–ç•¥ï¼š
        1. è®¡ç®—å½“å‰1çš„æ•°é‡å’Œç›®æ ‡æ•°é‡çš„å·®å€¼
        2. åŸºäºpromptç”Ÿæˆç¡®å®šæ€§çš„ä½ç½®åºåˆ—
        3. æŒ‰åºåˆ—ç¿»è½¬å¯¹åº”ä½ç½®çš„æ¯”ç‰¹ï¼Œç›´åˆ°è¾¾åˆ°ä¸¥æ ¼0.5åˆ†å¸ƒ
        
        Args:
            K_sem: åŸå§‹è¯­ä¹‰å¯†é’¥
            prompt: æç¤ºè¯ï¼ˆç”¨äºç”Ÿæˆç¡®å®šæ€§æ ¡æ­£åºåˆ—ï¼‰
            global_seed: å…¨å±€ç§å­
            
        Returns:
            æ ¡æ­£åçš„è¯­ä¹‰å¯†é’¥ï¼ˆä¸¥æ ¼0.5åˆ†å¸ƒï¼‰
        """
        total_bits = len(K_sem)
        target_ones = total_bits // 2  # ä¸¥æ ¼çš„ä¸€åŠ
        current_ones = (K_sem == 1).sum()
        
        print(f"    ğŸ”§ åˆ†å¸ƒæ ¡æ­£: å½“å‰1çš„æ•°é‡={current_ones}, ç›®æ ‡={target_ones}")
        
        if current_ones == target_ones:
            print(f"    âœ… å·²æ˜¯å®Œç¾åˆ†å¸ƒï¼Œæ— éœ€æ ¡æ­£")
            return K_sem
        
        # åˆ›å»ºå‰¯æœ¬è¿›è¡Œæ ¡æ­£
        K_sem_corrected = K_sem.copy()
        
        # ç”Ÿæˆç¡®å®šæ€§çš„æ ¡æ­£ä½ç½®åºåˆ—
        correction_seed = hash(f"{prompt}_{global_seed}_correction") & 0x7FFFFFFF
        rng = np.random.RandomState(correction_seed)
        position_sequence = rng.permutation(total_bits)
        
        if current_ones > target_ones:
            # éœ€è¦å°†ä¸€äº›1æ”¹ä¸º0
            excess_ones = current_ones - target_ones
            ones_positions = np.where(K_sem_corrected == 1)[0]
            # æŒ‰ç¡®å®šæ€§åºåˆ—é€‰æ‹©è¦ç¿»è½¬çš„ä½ç½®
            positions_to_flip = []
            for pos in position_sequence:
                if pos in ones_positions and len(positions_to_flip) < excess_ones:
                    positions_to_flip.append(pos)
            K_sem_corrected[positions_to_flip] = 0
            print(f"    ğŸ”„ ç¿»è½¬{len(positions_to_flip)}ä¸ª1â†’0")
            
        elif current_ones < target_ones:
            # éœ€è¦å°†ä¸€äº›0æ”¹ä¸º1
            deficit_ones = target_ones - current_ones
            zeros_positions = np.where(K_sem_corrected == 0)[0]
            # æŒ‰ç¡®å®šæ€§åºåˆ—é€‰æ‹©è¦ç¿»è½¬çš„ä½ç½®
            positions_to_flip = []
            for pos in position_sequence:
                if pos in zeros_positions and len(positions_to_flip) < deficit_ones:
                    positions_to_flip.append(pos)
            K_sem_corrected[positions_to_flip] = 1
            print(f"    ğŸ”„ ç¿»è½¬{len(positions_to_flip)}ä¸ª0â†’1")
        
        # éªŒè¯æ ¡æ­£ç»“æœ
        final_ones = (K_sem_corrected == 1).sum()
        final_ratio = final_ones / total_bits
        print(f"    âœ… æ ¡æ­£å®Œæˆ: 1çš„æ•°é‡={final_ones}, æ¯”ä¾‹={final_ratio:.6f}")
        
        return K_sem_corrected
    
    def _apply_final_distribution_correction(self, W_loc_final: np.ndarray, prompt: str) -> np.ndarray:
        """
        åº”ç”¨æœ€ç»ˆåˆ†å¸ƒæ ¡æ­£ï¼Œç¡®ä¿XORåçš„ç»“æœä¸¥æ ¼æ»¡è¶³0.5åˆ†å¸ƒ
        
        è¿™æ˜¯å…³é”®ä¿®å¤ï¼šå³ä½¿P_baseå’ŒK_seméƒ½æ˜¯0.5åˆ†å¸ƒï¼ŒXORåä¹Ÿå¯èƒ½æœ‰å¾®å°åå·®
        """
        total_bits = len(W_loc_final)
        target_ones = total_bits // 2  # ä¸¥æ ¼çš„ä¸€åŠ
        current_ones = (W_loc_final == 1).sum()
        
        print(f"    ğŸ”§ æœ€ç»ˆæ ¡æ­£: å½“å‰1çš„æ•°é‡={current_ones}, ç›®æ ‡={target_ones}")
        
        if current_ones == target_ones:
            print(f"    âœ… å·²æ˜¯å®Œç¾åˆ†å¸ƒï¼Œæ— éœ€æ ¡æ­£")
            return W_loc_final
        
        # åˆ›å»ºå‰¯æœ¬è¿›è¡Œæ ¡æ­£
        W_loc_corrected = W_loc_final.copy()
        
        # ç”Ÿæˆç¡®å®šæ€§çš„æ ¡æ­£ä½ç½®åºåˆ—ï¼ˆåŸºäºpromptç¡®ä¿ä¸€è‡´æ€§ï¼‰
        correction_seed = hash(f"{prompt}_final_correction") & 0x7FFFFFFF
        rng = np.random.RandomState(correction_seed)
        position_sequence = rng.permutation(total_bits)
        
        if current_ones > target_ones:
            # éœ€è¦å°†ä¸€äº›1æ”¹ä¸º0
            excess_ones = current_ones - target_ones
            ones_positions = np.where(W_loc_corrected == 1)[0]
            # æŒ‰ç¡®å®šæ€§åºåˆ—é€‰æ‹©è¦ç¿»è½¬çš„ä½ç½®
            positions_to_flip = []
            for pos in position_sequence:
                if pos in ones_positions and len(positions_to_flip) < excess_ones:
                    positions_to_flip.append(pos)
            W_loc_corrected[positions_to_flip] = 0
            print(f"    ğŸ”„ ç¿»è½¬{len(positions_to_flip)}ä¸ª1â†’0")
            
        elif current_ones < target_ones:
            # éœ€è¦å°†ä¸€äº›0æ”¹ä¸º1
            deficit_ones = target_ones - current_ones
            zeros_positions = np.where(W_loc_corrected == 0)[0]
            # æŒ‰ç¡®å®šæ€§åºåˆ—é€‰æ‹©è¦ç¿»è½¬çš„ä½ç½®
            positions_to_flip = []
            for pos in position_sequence:
                if pos in zeros_positions and len(positions_to_flip) < deficit_ones:
                    positions_to_flip.append(pos)
            W_loc_corrected[positions_to_flip] = 1
            print(f"    ğŸ”„ ç¿»è½¬{len(positions_to_flip)}ä¸ª0â†’1")
        
        # éªŒè¯æ ¡æ­£ç»“æœ
        final_ones = (W_loc_corrected == 1).sum()
        final_ratio = final_ones / total_bits
        print(f"    âœ… æœ€ç»ˆæ ¡æ­£å®Œæˆ: 1çš„æ•°é‡={final_ones}, æ¯”ä¾‹={final_ratio:.6f}")
        
        return W_loc_corrected
    
    def _compute_patch_semantic_seed(self, prompt: str, patch_idx: int, global_seed: int) -> int:
        """
        è®¡ç®—patchçº§è¯­ä¹‰ç§å­
        
        ç»“åˆpromptå†…å®¹ã€patchä½ç½®ç”Ÿæˆé«˜è´¨é‡çš„ç¡®å®šæ€§ç§å­
        """
        # åŸºç¡€ç§å­ï¼šå…¨å±€ç§å­ + patchç´¢å¼•
        base_seed = global_seed + patch_idx * 1000
        
        # å¦‚æœæœ‰promptï¼Œè¿›ä¸€æ­¥ç»“åˆå†…å®¹ç‰¹å¾
        if prompt:
            # æå–promptçš„å…³é”®ç‰¹å¾
            prompt_words = prompt.lower().split()
            
            # è®¡ç®—è¯¥patchå¯¹åº”çš„promptç‰¹å¾
            word_influences = []
            for word_idx, word in enumerate(prompt_words[:10]):  # é™åˆ¶å‰10ä¸ªè¯
                word_hash = hash(word) & 0xFFFFFFFF
                patch_influence = (word_hash + patch_idx) % 1000000
                word_influences.append(patch_influence)
            
            # ç»“åˆæ‰€æœ‰è¯æ±‡å½±å“
            content_influence = sum(word_influences) % 1000000 if word_influences else 0
            
            # å¤šå±‚å“ˆå¸Œç”Ÿæˆæœ€ç»ˆç§å­
            combined_input = f"{base_seed}_{content_influence}_{patch_idx}_{len(prompt_words)}"
            final_hash = int(hashlib.md5(combined_input.encode()).hexdigest()[:8], 16)
            final_seed = final_hash & 0x7FFFFFFF
        else:
            final_seed = base_seed & 0x7FFFFFFF
        
        return final_seed
    
    def _generate_patch_key_bits(self, seed: int, length: int) -> np.ndarray:
        """
        åŸºäºç§å­ç”Ÿæˆé«˜è´¨é‡çš„ä¼ªéšæœºå¯†é’¥æ¯”ç‰¹
        """
        # ä½¿ç”¨numpyçš„é«˜è´¨é‡éšæœºæ•°ç”Ÿæˆå™¨
        rng = np.random.RandomState(seed)
        key_bits = rng.randint(0, 2, size=length, dtype=np.int32)
        return key_bits
    
    def generate_initial_noise_tagwm(self, w_cop: torch.Tensor, w_loc: torch.Tensor) -> torch.Tensor:
        """ä½¿ç”¨TAG-WMå®Œæ•´æµç¨‹ç”Ÿæˆåˆå§‹å™ªå£°"""
        print("ğŸ² ç”ŸæˆTAG-WMæ ‡å‡†åˆå§‹å™ªå£°...")
        
        if self.tag_wm_embedder is not None:
            try:
                # 1. æ•°æ®ç±»å‹è½¬æ¢ï¼šç¡®ä¿wmæ˜¯intå‹torch.Tensor
                wm = w_cop.int().to(self.device)
                
                # 2. TLTç”Ÿæˆï¼šç›´æ¥ä½¿ç”¨SEAL-LOCæœ€ç»ˆå®šä½æ°´å°
                latent_size = w_loc.shape  # (4, 64, 64)
                latent_len = w_loc.numel()  # 4*64*64 = 16384
                
                # ç›´æ¥ä½¿ç”¨W_loc_finalä½œä¸ºTLTï¼ˆå·²å…·å¤‡å®Œç¾ç»Ÿè®¡ç‰¹æ€§ï¼‰
                tlt = w_loc.flatten().cpu().numpy().astype(np.int32)
                
                print(f"  ğŸ“Š wmå½¢çŠ¶: {wm.shape}, dtype: {wm.dtype}")
                print(f"  ğŸ“Š tltå½¢çŠ¶: {tlt.shape}, dtype: {tlt.dtype}")
                print(f"  ğŸ“Š tltå€¼åŸŸ: [{tlt.min()}, {tlt.max()}]")
                print(f"  ğŸ“Š tltä¸­1çš„æ¯”ä¾‹: {(tlt == 1).sum() / len(tlt):.4f}")
                print(f"  ğŸ“Š latent_size: {latent_size}")
                print(f"  ğŸ¯ ä½¿ç”¨SEAL-LOCæœ€ç»ˆå®šä½æ°´å°ä½œä¸ºTLT")
                
                # 3. ä½¿ç”¨TAG-WMå®Œæ•´çš„embedding_wm_tltæ–¹æ³•
                latent_noise, wm_repeat = self.tag_wm_embedder.embedding_wm_tlt(
                    wm=wm, 
                    tlt=tlt, 
                    latent_size=latent_size
                )
                
                print("âœ… ä½¿ç”¨TAG-WMå®Œæ•´åµŒå…¥æµç¨‹æˆåŠŸ")
                print(f"âœ… latent_noiseå½¢çŠ¶: {latent_noise.shape}")
                print(f"âœ… wm_repeaté•¿åº¦: {len(wm_repeat)}")
                
                return latent_noise
                
            except Exception as e:
                print(f"âŒ TAG-WMåµŒå…¥å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                # å¤‡ç”¨æ–¹æ¡ˆï¼šç®€å•çš„æ­£æ€åˆ†å¸ƒå™ªå£°
                latent_noise = torch.randn(1, *w_loc.shape, device=self.device, dtype=torch.float16)
        else:
            print("âš ï¸ TAG-WM embedderä¸å¯ç”¨ï¼Œä½¿ç”¨å¤‡ç”¨å™ªå£°")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šç®€å•çš„æ­£æ€åˆ†å¸ƒå™ªå£°
            latent_noise = torch.randn(1, *w_loc.shape, device=self.device, dtype=torch.float16)
        
        print(f"âœ… åˆå§‹å™ªå£°ç”Ÿæˆå®Œæˆ (å½¢çŠ¶: {latent_noise.shape})")
        return latent_noise
    
    def generate_watermarked_image(self, prompt: str, latent_noise: torch.Tensor) -> Image.Image:
        """ç”Ÿæˆæ°´å°åŒ–å›¾åƒ"""
        print("ğŸ¨ ç”Ÿæˆæ°´å°åŒ–å›¾åƒ...")
        
        try:
            # ä½¿ç”¨æ°´å°åŒ–å™ªå£°ä½œä¸ºåˆå§‹latentsï¼Œå‚æ•°ä¸åŸå§‹TAG-WMä¿æŒä¸€è‡´
            image = self.pipe(
                prompt, 
                latents=latent_noise,
                guidance_scale=7.5,  # ä¸åŸå§‹TAG-WMä¸€è‡´
                num_inference_steps=50,  # ä¸åŸå§‹TAG-WMä¸€è‡´
                height=512,
                width=512
            ).images[0]
        except Exception as e:
            print(f"Warning: Using latents failed, generating normally: {e}")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šæ­£å¸¸ç”Ÿæˆ
            image = self.pipe(prompt).images[0]
        
        print("âœ… æ°´å°åŒ–å›¾åƒç”Ÿæˆå®Œæˆ")
        return image
    
    def calculate_bit_accuracy_simple(self, orig_w_cop: torch.Tensor, orig_w_loc: torch.Tensor,
                                    recon_w_cop: torch.Tensor, recon_w_loc: torch.Tensor) -> dict:
        """è®¡ç®—ç®€åŒ–çš„æ¯”ç‰¹ç²¾åº¦"""
        print("ğŸ“ è®¡ç®—æ¯”ç‰¹ç²¾åº¦...")
        print(f"  ğŸ” orig_w_copç±»å‹: {orig_w_cop.dtype}, recon_w_copç±»å‹: {recon_w_cop.dtype}")
        print(f"  ğŸ” orig_w_locç±»å‹: {orig_w_loc.dtype}, recon_w_locç±»å‹: {recon_w_loc.dtype}")
        
        # ç‰ˆæƒæ°´å°ç²¾åº¦
        cop_accuracy = (orig_w_cop == recon_w_cop).float().mean().item()
        
        # å®šä½æ°´å°ç²¾åº¦
        loc_accuracy = (orig_w_loc == recon_w_loc).float().mean().item()
        
        # L2è·ç¦»
        l2_distance = calculate_patch_l2_fallback(orig_w_loc, recon_w_loc, k=64)
        
        metrics = {
            'copyright_accuracy': cop_accuracy,
            'location_accuracy': loc_accuracy,
            'l2_distance': l2_distance,
            'total_bits_cop': len(orig_w_cop),
            'total_bits_loc': orig_w_loc.numel(),
            'correct_bits_cop': int((orig_w_cop == recon_w_cop).sum()),
            'correct_bits_loc': int((orig_w_loc == recon_w_loc).sum())
        }
        
        print(f"ğŸ“Š ç‰ˆæƒæ°´å°ç²¾åº¦: {cop_accuracy:.4f}")
        print(f"ğŸ“Š å®šä½æ°´å°ç²¾åº¦: {loc_accuracy:.4f}")
        print(f"ğŸ“Š L2è·ç¦»: {l2_distance:.4f}")
        
        return metrics
    
    def run_simple_test(self, prompt: str = "A beautiful landscape with mountains and trees", 
                       output_dir: str = "output/simple_test") -> dict:
        """è¿è¡Œç®€åŒ–æµ‹è¯•æµç¨‹"""
        print("ğŸš€ å¼€å§‹ç®€åŒ–SEAL-LOCæµ‹è¯•æµç¨‹")
        print(f"ğŸ“ æµ‹è¯•æç¤ºè¯: {prompt}")
        
        os.makedirs(output_dir, exist_ok=True)
        start_time = time.time()
        
        try:
            # 1. åŠ è½½æ‰©æ•£æ¨¡å‹
            if self.pipe is None:
                self.load_diffusion_model()
            
            # 2. ç”Ÿæˆç‰ˆæƒæ°´å°
            w_cop = self.generate_copyright_watermark()
            
            # 3. ç”ŸæˆSEAL-LOCè¯­ä¹‰å®šä½æ°´å°
            latent_size = (4, 64, 64)
            w_loc = self.generate_semantic_location_watermark(latent_size, prompt)
            
            # 4. ç”Ÿæˆåˆå§‹å™ªå£°
            latent_noise = self.generate_initial_noise_tagwm(w_cop, w_loc)
            
            # 5. ç”Ÿæˆæ°´å°åŒ–å›¾åƒ
            watermarked_image = self.generate_watermarked_image(prompt, latent_noise)
            
            # 6. çœŸå®çš„æ°´å°é‡å»ºï¼ˆä½¿ç”¨TAG-WMæ–¹æ³•ï¼‰
            print("ğŸ” æ‰§è¡Œæ°´å°é‡å»º...")
            try:
                # å°†å›¾åƒè½¬æ¢ä¸ºtensor
                from torchvision import transforms
                transform = transforms.Compose([
                    transforms.Resize(512),
                    transforms.CenterCrop(512),
                    transforms.ToTensor(),
                ])
                image_tensor = transform(watermarked_image).unsqueeze(0).to(self.device)
                image_tensor = 2.0 * image_tensor - 1.0  # å½’ä¸€åŒ–åˆ°[-1, 1]
                image_tensor = image_tensor.to(dtype=torch.float16)
                
                # è·å–å›¾åƒçš„latentè¡¨ç¤º
                with torch.no_grad():
                    image_latents = self.pipe.vae.encode(image_tensor).latent_dist.sample()
                    image_latents = image_latents * self.pipe.vae.config.scaling_factor
                
                # ç®€åŒ–çš„"åè½¬"ï¼šç›´æ¥ä½¿ç”¨ç¼–ç å¾—åˆ°çš„latentsä½œä¸ºé‡å»ºå™ªå£°
                # åœ¨çœŸå®åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥æ˜¯DDIMåè½¬è¿‡ç¨‹
                reconstructed_noise = image_latents.squeeze(0)  # ç§»é™¤batchç»´åº¦
                
                # ä½¿ç”¨TAG-WMçš„åé‡‡æ ·æ–¹æ³•é‡å»ºæ°´å°
                if self.tag_wm_embedder is not None:
                    # å±•å¹³å™ªå£°
                    noise_flat = reconstructed_noise.flatten()
                    
                    # åæ‰“ä¹±
                    noise_flat = self.tag_wm_embedder.inverse_shuffle(noise_flat)
                    
                    # åé‡‡æ ·å¾—åˆ°æ°´å°æ¯”ç‰¹
                    recon_w_cop_expanded, recon_w_loc_flat = self.tag_wm_embedder.reverseTruncSampling(noise_flat)
                    
                    # ç¡®ä¿é‡å»ºçš„æ°´å°åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
                    recon_w_cop_expanded = recon_w_cop_expanded.to(self.device)
                    recon_w_loc_flat = recon_w_loc_flat.to(self.device)
                    
                    # å¤„ç†ç‰ˆæƒæ°´å°ï¼šä»æ‰©å±•çš„æ°´å°ä¸­æ¢å¤åŸå§‹æ°´å°
                    # ä½¿ç”¨å¤šæ•°æŠ•ç¥¨æœºåˆ¶ä»é‡å¤çš„æ°´å°ä¸­æ¢å¤
                    original_len = len(w_cop)
                    recon_w_cop = torch.zeros(original_len, device=self.device)
                    
                    for i in range(original_len):
                        # æ”¶é›†æ‰€æœ‰é‡å¤ä½ç½®çš„æ¯”ç‰¹å€¼
                        votes = []
                        for j in range(i, len(recon_w_cop_expanded), original_len):
                            votes.append(recon_w_cop_expanded[j].item())
                        
                        # å¤šæ•°æŠ•ç¥¨
                        recon_w_cop[i] = 1 if sum(votes) > len(votes) / 2 else 0
                    
                    # é‡å¡‘å®šä½æ°´å°å½¢çŠ¶
                    recon_w_loc = recon_w_loc_flat[:w_loc.numel()].reshape(w_loc.shape).to(self.device)
                    
                    print("âœ… ä½¿ç”¨TAG-WMåé‡‡æ ·é‡å»ºæˆåŠŸ")
                else:
                    raise Exception("TAG-WM embedder not available")
                    
            except Exception as e:
                print(f"Warning: çœŸå®é‡å»ºå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿé‡å»º: {e}")
                # å›é€€åˆ°æ¨¡æ‹Ÿé‡å»º
                recon_w_cop = w_cop.clone().to(self.device)
                recon_w_loc = w_loc.clone().to(self.device)
                
                # æ·»åŠ ä¸€äº›å™ªå£°æ¨¡æ‹Ÿé‡å»ºè¯¯å·®
                error_rate = 0.02  # é™ä½åˆ°2%é”™è¯¯ç‡
                cop_errors = int(len(w_cop) * error_rate)
                loc_errors = int(w_loc.numel() * error_rate)
                
                # éšæœºç¿»è½¬ä¸€äº›æ¯”ç‰¹
                if cop_errors > 0:
                    error_indices = torch.randperm(len(w_cop), device=self.device)[:cop_errors]
                    recon_w_cop[error_indices] = 1 - recon_w_cop[error_indices]
                
                if loc_errors > 0:
                    flat_loc = recon_w_loc.flatten()
                    error_indices = torch.randperm(len(flat_loc), device=self.device)[:loc_errors]
                    flat_loc[error_indices] = 1 - flat_loc[error_indices]
                    recon_w_loc = flat_loc.reshape(w_loc.shape)
            
            # 7. è®¡ç®—ç²¾åº¦
            metrics = self.calculate_bit_accuracy_simple(w_cop, w_loc, recon_w_cop, recon_w_loc)
            
            # 8. ä¿å­˜ç»“æœ
            self.save_simple_results(output_dir, prompt, watermarked_image, metrics)
            
            end_time = time.time()
            total_time = end_time - start_time
            metrics['total_time'] = total_time
            
            print(f"âœ… ç®€åŒ–æµ‹è¯•æµç¨‹å®Œæˆï¼è€—æ—¶: {total_time:.2f}ç§’")
            return metrics
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•æµç¨‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise e
    
    def save_simple_results(self, output_dir: str, prompt: str, image: Image.Image, metrics: dict):
        """ä¿å­˜ç®€åŒ–æµ‹è¯•ç»“æœ"""
        print("ğŸ’¾ ä¿å­˜æµ‹è¯•ç»“æœ...")
        
        # ä¿å­˜å›¾åƒ
        image_path = os.path.join(output_dir, "watermarked_image.png")
        image.save(image_path)
        
        # ä¿å­˜metrics
        metrics_path = os.path.join(output_dir, "metrics.txt")
        with open(metrics_path, 'w') as f:
            f.write(f"SEAL-LOC Simple Test Results\n")
            f.write(f"============================\n")
            f.write(f"Prompt: {prompt}\n")
            f.write(f"Copyright Watermark Accuracy: {metrics['copyright_accuracy']:.4f}\n")
            f.write(f"Location Watermark Accuracy: {metrics['location_accuracy']:.4f}\n")
            f.write(f"L2 Distance: {metrics['l2_distance']:.4f}\n")
            f.write(f"Total Time: {metrics.get('total_time', 0):.2f}s\n")
            f.write(f"Correct Copyright Bits: {metrics['correct_bits_cop']}/{metrics['total_bits_cop']}\n")
            f.write(f"Correct Location Bits: {metrics['correct_bits_loc']}/{metrics['total_bits_loc']}\n")
        
        print(f"âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")


def main():
    parser = argparse.ArgumentParser(description='SEAL-LOC Simple Test')
    parser.add_argument('--prompt', type=str, 
                       default="A beautiful landscape with mountains and trees",
                       help='æµ‹è¯•æç¤ºè¯')
    parser.add_argument('--device', type=str, default='cuda', 
                       help='è®¾å¤‡ (cuda/cpu)')
    parser.add_argument('--model_id', type=str, 
                       default='stabilityai/stable-diffusion-2-1-base',
                       help='æ‰©æ•£æ¨¡å‹ID')
    parser.add_argument('--output_dir', type=str, 
                       default='output/simple_test',
                       help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print("ğŸ”§ ç®€åŒ–æµ‹è¯•æ¨¡å¼ - é¿å…å¤æ‚ä¾èµ–")
    
    # åˆå§‹åŒ–æµ‹è¯•ç³»ç»Ÿ
    tester = SimpleSEALLOCTest(device=args.device, model_id=args.model_id)
    
    # è¿è¡Œæµ‹è¯•
    try:
        metrics = tester.run_simple_test(
            prompt=args.prompt,
            output_dir=args.output_dir
        )
        
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"ç‰ˆæƒæ°´å°ç²¾åº¦: {metrics['copyright_accuracy']:.4f}")
        print(f"å®šä½æ°´å°ç²¾åº¦: {metrics['location_accuracy']:.4f}")
        print(f"L2è·ç¦»: {metrics['l2_distance']:.4f}")
        print(f"è€—æ—¶: {metrics['total_time']:.2f}ç§’")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return 1
    
    print("ğŸ‰ ç®€åŒ–æµ‹è¯•å®Œæˆï¼")
    return 0


if __name__ == "__main__":
    exit(main()) 