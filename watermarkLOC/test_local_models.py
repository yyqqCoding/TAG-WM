"""
æµ‹è¯•æœ¬åœ°æ¨¡å‹åŠ è½½

éªŒè¯æ‰€æœ‰æœ¬åœ°æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæ¨¡å‹æ˜¯å¦èƒ½å¤Ÿæ­£å¸¸åŠ è½½
"""

import os
import torch
from model_config import get_model_path, check_model_exists

def test_model_paths():
    """æµ‹è¯•æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨"""
    print("ğŸ” æ£€æŸ¥æœ¬åœ°æ¨¡å‹è·¯å¾„...")
    
    models_to_check = [
        "stabilityai/stable-diffusion-2-1-base",
        "Salesforce/blip2-flan-t5-xl", 
        "laion/CLIP-ViT-g-14-laion2B-s12B-b42K",
        "kasraarabi/finetuned-caption-embedding"
    ]
    
    for model_name in models_to_check:
        model_path = get_model_path(model_name)
        exists = check_model_exists(model_path)
        status = "âœ…" if exists else "âŒ"
        print(f"{status} {model_name}")
        print(f"   è·¯å¾„: {model_path}")
        if not exists:
            print(f"   é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨")
        print()

def test_diffusers_loading():
    """æµ‹è¯•diffusersæ¨¡å‹åŠ è½½"""
    print("ğŸ”„ æµ‹è¯•Stable Diffusionæ¨¡å‹åŠ è½½...")
    
    try:
        from diffusers import StableDiffusionPipeline
        
        model_path = get_model_path("stabilityai/stable-diffusion-2-1-base")
        print(f"ğŸ“ ä»è·¯å¾„åŠ è½½: {model_path}")
        
        # æµ‹è¯•åŠ è½½ï¼ˆä¸ç§»åŠ¨åˆ°GPUä»¥èŠ‚çœå†…å­˜ï¼‰
        pipe = StableDiffusionPipeline.from_pretrained(
            model_path,
            torch_dtype=torch.float16,
            local_files_only=True,
            device_map=None  # ä¸è‡ªåŠ¨ç§»åŠ¨åˆ°è®¾å¤‡
        )
        
        print("âœ… Stable Diffusionæ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"   æ¨¡å‹ç±»å‹: {type(pipe)}")
        
        # æ¸…ç†å†…å­˜
        del pipe
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
        
        return True
        
    except Exception as e:
        print(f"âŒ Stable Diffusionæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def test_transformers_loading():
    """æµ‹è¯•transformersæ¨¡å‹åŠ è½½"""
    print("ğŸ”„ æµ‹è¯•BLIP-2æ¨¡å‹åŠ è½½...")
    
    try:
        from transformers import Blip2Processor, Blip2ForConditionalGeneration
        
        model_path = get_model_path("Salesforce/blip2-flan-t5-xl")
        print(f"ğŸ“ ä»è·¯å¾„åŠ è½½: {model_path}")
        
        # æµ‹è¯•processoråŠ è½½
        processor = Blip2Processor.from_pretrained(
            model_path,
            local_files_only=True
        )
        print("âœ… BLIP-2 ProcessoråŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•æ¨¡å‹åŠ è½½ï¼ˆä¸ç§»åŠ¨åˆ°GPUï¼‰
        model = Blip2ForConditionalGeneration.from_pretrained(
            model_path,
            torch_dtype=torch.float16,
            local_files_only=True,
            device_map=None
        )
        print("âœ… BLIP-2 ModelåŠ è½½æˆåŠŸ")
        print(f"   æ¨¡å‹ç±»å‹: {type(model)}")
        
        # æ¸…ç†å†…å­˜
        del processor, model
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
        
        return True
        
    except Exception as e:
        print(f"âŒ BLIP-2æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def test_sentence_transformer_loading():
    """æµ‹è¯•SentenceTransformeråŠ è½½"""
    print("ğŸ”„ æµ‹è¯•SentenceTransformeræ¨¡å‹åŠ è½½...")
    
    try:
        from sentence_transformers import SentenceTransformer
        
        model_path = get_model_path("kasraarabi/finetuned-caption-embedding")
        print(f"ğŸ“ ä»æœ¬åœ°è·¯å¾„åŠ è½½: {model_path}")
        
        # å°è¯•ä»æœ¬åœ°è·¯å¾„åŠ è½½
        model = SentenceTransformer(model_path)
        print("âœ… SentenceTransformeræœ¬åœ°åŠ è½½æˆåŠŸ")
        print(f"   æ¨¡å‹ç±»å‹: {type(model)}")
        
        # ç®€å•æµ‹è¯•
        test_text = "A beautiful landscape"
        embedding = model.encode(test_text)
        print(f"   æµ‹è¯•ç¼–ç ç»´åº¦: {embedding.shape}")
        
        # æ¸…ç†å†…å­˜
        del model
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
        
        return True
        
    except Exception as e:
        print(f"âŒ SentenceTransformeræœ¬åœ°åŠ è½½å¤±è´¥: {e}")
        print("ğŸ”„ å°è¯•åœ¨çº¿åŠ è½½...")
        try:
            model = SentenceTransformer("kasraarabi/finetuned-caption-embedding")
            print("âœ… SentenceTransformeråœ¨çº¿åŠ è½½æˆåŠŸ")
            
            # ç®€å•æµ‹è¯•
            test_text = "A beautiful landscape"
            embedding = model.encode(test_text)
            print(f"   æµ‹è¯•ç¼–ç ç»´åº¦: {embedding.shape}")
            
            # æ¸…ç†å†…å­˜
            del model
            torch.cuda.empty_cache() if torch.cuda.is_available() else None
            
            return True
        except Exception as e2:
            print(f"âŒ SentenceTransformeråœ¨çº¿åŠ è½½ä¹Ÿå¤±è´¥: {e2}")
            return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª SEAL-LOC æœ¬åœ°æ¨¡å‹åŠ è½½æµ‹è¯•")
    print("=" * 50)
    
    # 1. æ£€æŸ¥è·¯å¾„
    test_model_paths()
    
    # 2. æµ‹è¯•å„ä¸ªæ¨¡å‹åŠ è½½
    results = {}
    
    print("ğŸ”§ å¼€å§‹æ¨¡å‹åŠ è½½æµ‹è¯•...")
    print("-" * 30)
    
    results['diffusers'] = test_diffusers_loading()
    print()
    
    results['transformers'] = test_transformers_loading() 
    print()
    
    results['sentence_transformer'] = test_sentence_transformer_loading()
    print()
    
    # 3. æ€»ç»“ç»“æœ
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print("-" * 30)
    
    for test_name, success in results.items():
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
    
    all_passed = all(results.values())
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥è¿è¡ŒSEAL-LOCæµ‹è¯•äº†")
        print("   å»ºè®®è¿è¡Œ: python simple_test.py")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œä½†å¯èƒ½ä»å¯è¿è¡Œç®€åŒ–ç‰ˆæœ¬")
        print("   å¯ä»¥å°è¯•: python simple_test.py --device cpu")
    
    return 0 if all_passed else 1

if __name__ == "__main__":
    exit(main()) 