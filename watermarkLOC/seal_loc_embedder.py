"""
SEAL-LOC: Semantic-Aware Localization Watermark Embedder

åŸºäºè¯­ä¹‰çš„å®šä½æ°´å°åµŒå…¥å™¨ï¼Œé›†æˆSEALçš„è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›ä¸TAG-WMçš„åŒæ°´å°æ¶æ„ã€‚
æ ¸å¿ƒç‰¹æ€§ï¼š
- ç»§æ‰¿TAG-WMçš„åŒæ°´å°æ¶æ„å’ŒDMJSç®—æ³•
- å®ç°é€è¡¥ä¸è¯­ä¹‰ç‰¹å¾æå–
- åŠ¨æ€ç”Ÿæˆä¸å†…å®¹ç»‘å®šçš„è¯­ä¹‰å®šä½æ°´å°
- ä¿æŒä¸åŸæœ‰ç³»ç»Ÿçš„å®Œå…¨å…¼å®¹æ€§
"""

import torch
import torch.nn as nn
import numpy as np
import os
import math
import hashlib
from typing import Tuple, List, Optional
from PIL import Image
from transformers import Blip2Processor, Blip2ForConditionalGeneration
from sentence_transformers import SentenceTransformer
from model_config import get_model_path, check_model_exists

# å¯¼å…¥TAG-WMçš„æ ¸å¿ƒç»„ä»¶
import sys
sys.path.append('../applied_to_sd2')

# ä¸´æ—¶ç¦ç”¨DVRDå¯¼å…¥ä»¥é¿å…ä¾èµ–é—®é¢˜
import os
os.environ['DISABLE_DVRD'] = '1'
from watermark_embedder import WatermarkEmbedder

# å¯¼å…¥æœ¬åœ°çš„å›¾åƒæè¿°ç”Ÿæˆå‡½æ•°
from caption_utils import generate_caption


class SEALLOCEmbedder(WatermarkEmbedder):
    """
    è¯­ä¹‰åŒºåŸŸæ„ŸçŸ¥å®šä½æ°´å°åµŒå…¥å™¨ (SEAL-LOC)
    
    æ ¸å¿ƒåˆ›æ–°ï¼š
    - å°†å®šä½æ°´å°ä»å›ºå®šæ¨¡æ¿(TLT)å‡çº§ä¸ºåŠ¨æ€è¯­ä¹‰ç»‘å®šæ¨¡æ¿(W_loc^S)
    - æ¯ä¸ªpatchçš„æ°´å°æ¨¡å¼ä¸å…¶è¯­ä¹‰å†…å®¹å¯†ç å­¦çº§åˆ«ç»‘å®š
    - ä¿æŒTAG-WMçš„ç‰ˆæƒæ°´å°(W_cop)å’ŒDMJSé‡‡æ ·æœºåˆ¶ä¸å˜
    """
    
    def __init__(self, 
                 # ç»§æ‰¿TAG-WMçš„æ‰€æœ‰å‚æ•°
                 wm_len=256,
                 center_interval_ratio=0.5,
                 shuffle_random_seed=133563,
                 encrypt_random_seed=133563,
                 tlt_intervals_num=3,  # ä½¿ç”¨ä¸‰åŒºé—´ç­–ç•¥
                 fpr=1e-6,
                 user_number=1000000,
                 optimize_tamper_loc_method=None,
                 DVRD_checkpoint_path=None,
                 DVRD_train_size=512,
                 device='cuda',
                 # SEAL-LOCç‰¹æœ‰å‚æ•°
                 patch_grid_size=8,  # 8x8ç½‘æ ¼ï¼Œå…±64ä¸ªpatch
                 semantic_vector_dim=768,  # SentenceTransformerè¾“å‡ºç»´åº¦
                 simhash_bits=7,  # SimHashæ¯”ç‰¹æ•°
                 semantic_maps_dir='watermarkLOC/semantic_maps/',  # è¯­ä¹‰åœ°å›¾å­˜å‚¨è·¯å¾„
                 vlm_model_name='blip2-flan-t5-xl',  # VLMæ¨¡å‹
                 sentence_model_name='kasraarabi/finetuned-caption-embedding',  # è¯­ä¹‰ç¼–ç æ¨¡å‹
                 ):
        
        # åˆå§‹åŒ–çˆ¶ç±»
        super(SEALLOCEmbedder, self).__init__(
            wm_len=wm_len,
            center_interval_ratio=center_interval_ratio,
            shuffle_random_seed=shuffle_random_seed,
            encrypt_random_seed=encrypt_random_seed,
            tlt_intervals_num=tlt_intervals_num,
            fpr=fpr,
            user_number=user_number,
            optimize_tamper_loc_method=optimize_tamper_loc_method,
            DVRD_checkpoint_path=DVRD_checkpoint_path,
            DVRD_train_size=DVRD_train_size,
            device=device
        )
        
        # SEAL-LOCç‰¹æœ‰é…ç½®
        self.patch_grid_size = patch_grid_size
        self.num_patches = patch_grid_size * patch_grid_size  # 64ä¸ªpatch
        self.semantic_vector_dim = semantic_vector_dim
        self.simhash_bits = simhash_bits
        self.semantic_maps_dir = semantic_maps_dir
        
        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        os.makedirs(semantic_maps_dir, exist_ok=True)
        
        # åˆå§‹åŒ–VLMå’Œè¯­ä¹‰ç¼–ç æ¨¡å‹
        model_path = get_model_path(vlm_model_name)
        print(f"  - Loading VLM model: {vlm_model_name} from {model_path}")
        
        # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not check_model_exists(model_path):
            print(f"  âš ï¸ Model path does not exist: {model_path}")
            print("  è¯·ç¡®ä¿å·²å°†æ¨¡å‹ä¸‹è½½åˆ°æŒ‡å®šè·¯å¾„")
        
        # å°è¯•è§£å†³BLIP-2 tokenizeré—®é¢˜çš„å¤šç§æ–¹æ³•
        try:
            # æ–¹æ³•1: ä»æœ¬åœ°è·¯å¾„åŠ è½½
            self.vlm_processor = Blip2Processor.from_pretrained(
                model_path,
                trust_remote_code=True,
                local_files_only=True
            )
            self.vlm_model = Blip2ForConditionalGeneration.from_pretrained(
                model_path, 
                torch_dtype=torch.float16,
                trust_remote_code=True,
                local_files_only=True
            ).to(device)
            print("  âœ… VLM loaded successfully from local path")
        except Exception as e1:
            print(f"  âš ï¸ Local loading failed: {e1}")
            try:
                # æ–¹æ³•2: ä½¿ç”¨è¾ƒå°çš„BLIP-2æ¨¡å‹
                fallback_model_path = get_model_path("blip2-opt-2.7b")
                print(f"  ğŸ”„ Trying fallback model: {fallback_model_path}")
                self.vlm_processor = Blip2Processor.from_pretrained(
                    fallback_model_path,
                    trust_remote_code=True,
                    local_files_only=True
                )
                self.vlm_model = Blip2ForConditionalGeneration.from_pretrained(
                    fallback_model_path, 
                    torch_dtype=torch.float16,
                    trust_remote_code=True,
                    local_files_only=True
                ).to(device)
                print("  âœ… VLM loaded successfully (fallback model)")
            except Exception as e2:
                print(f"  âŒ All VLM loading methods failed: {e2}")
                print("  è¯·ç¡®ä¿BLIP-2æ¨¡å‹å·²æ­£ç¡®ä¸‹è½½åˆ°æœ¬åœ°è·¯å¾„")
                raise RuntimeError("æ— æ³•åŠ è½½BLIP-2æ¨¡å‹ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        
        # åˆå§‹åŒ–SentenceTransformerï¼ˆæ”¯æŒæœ¬åœ°è·¯å¾„ï¼‰
        sentence_model_path = get_model_path(sentence_model_name)
        print(f"  - Loading SentenceTransformer: {sentence_model_name} from {sentence_model_path}")
        
        try:
            # å°è¯•ä»æœ¬åœ°è·¯å¾„åŠ è½½
            self.sentence_model = SentenceTransformer(sentence_model_path).to(device)
            print("  âœ… SentenceTransformer loaded successfully from local path")
        except Exception as e:
            print(f"  âš ï¸ Local SentenceTransformer loading failed: {e}")
            try:
                # å›é€€åˆ°åœ¨çº¿åŠ è½½
                self.sentence_model = SentenceTransformer(sentence_model_name).to(device)
                print("  âœ… SentenceTransformer loaded successfully from online")
            except Exception as e2:
                print(f"  âŒ All SentenceTransformer loading methods failed: {e2}")
                raise RuntimeError("æ— æ³•åŠ è½½SentenceTransformeræ¨¡å‹")
        
        print(f"SEAL-LOC Embedder initialized:")
        print(f"  - Patch grid: {patch_grid_size}x{patch_grid_size} = {self.num_patches} patches")
        print(f"  - Semantic vector dim: {semantic_vector_dim}")
        print(f"  - SimHash bits: {simhash_bits}")
        print(f"  - Semantic maps storage: {semantic_maps_dir}")
    
    def generate_proxy_image(self, prompt: str, pipe=None, num_inference_steps=20) -> Image.Image:
        """
        é˜¶æ®µä¸€ï¼šä»£ç†ç”Ÿæˆä¸åˆå§‹è¡¨ç¤º
        ç”Ÿæˆæ— æ°´å°çš„ä»£ç†å›¾åƒï¼Œç”¨äºåç»­è¯­ä¹‰æå–
        """
        if pipe is not None:
            with torch.no_grad():
                proxy_image = pipe(prompt).images[0]
        else:
            # ä½¿ç”¨å†…ç½®çš„VLMç”Ÿæˆç®€å•çš„ä»£ç†å›¾åƒ
            from diffusers import StableDiffusionPipeline
            temp_pipe = StableDiffusionPipeline.from_pretrained(
                "stabilityai/stable-diffusion-2-1",
                torch_dtype=torch.float16
            ).to(self.device)
            with torch.no_grad():
                proxy_image = temp_pipe(prompt, num_inference_steps=num_inference_steps).images[0]
            del temp_pipe  # é‡Šæ”¾å†…å­˜
        return proxy_image
    
    def extract_patch_semantics(self, proxy_image: Image.Image, latent_size: Tuple[int, int, int]) -> List[torch.Tensor]:
        """
        é˜¶æ®µäºŒï¼šé€è¡¥ä¸è¯­ä¹‰ç‰¹å¾æå–
        
        Args:
            proxy_image: ä»£ç†å›¾åƒ (512x512 RGB)
            latent_size: æ½œç©ºé—´å°ºå¯¸ (C, H, W) = (4, 64, 64)
            
        Returns:
            List of semantic vectors, one for each patch
        """
        _, latent_h, latent_w = latent_size
        patch_size_latent = latent_h // self.patch_grid_size  # 64 // 8 = 8
        patch_size_image = 512 // self.patch_grid_size  # 512 // 8 = 64
        
        semantic_vectors = []
        
        print(f"Extracting semantics for {self.num_patches} patches...")
        
        for i in range(self.patch_grid_size):
            for j in range(self.patch_grid_size):
                # è®¡ç®—patchåœ¨å›¾åƒç©ºé—´çš„ä½ç½®
                y_start = i * patch_size_image
                y_end = (i + 1) * patch_size_image
                x_start = j * patch_size_image
                x_end = (j + 1) * patch_size_image
                
                # è£å‰ªå¯¹åº”çš„å›¾åƒåŒºåŸŸ
                patch_image = proxy_image.crop((x_start, y_start, x_end, y_end))
                
                # ä½¿ç”¨VLMç”Ÿæˆè¯¥patchçš„æè¿°
                patch_caption = generate_caption(
                    patch_image, 
                    self.vlm_processor, 
                    self.vlm_model, 
                    device=self.device
                )
                
                # å°†æè¿°è½¬æ¢ä¸ºè¯­ä¹‰å‘é‡
                semantic_vector = self.sentence_model.encode(
                    patch_caption, 
                    convert_to_tensor=True
                ).to(self.device)
                
                # å½’ä¸€åŒ–è¯­ä¹‰å‘é‡
                semantic_vector = semantic_vector / torch.norm(semantic_vector)
                
                semantic_vectors.append(semantic_vector)
        
        print(f"Semantic extraction completed. Generated {len(semantic_vectors)} vectors.")
        return semantic_vectors
    
    def generate_dynamic_semantic_watermark(self, semantic_vectors: List[torch.Tensor], latent_size: Tuple[int, int, int]) -> torch.Tensor:
        """
        é˜¶æ®µä¸‰ï¼šåŠ¨æ€è¯­ä¹‰å®šä½æ°´å°ç”Ÿæˆ
        
        ä¸ºæ¯ä¸ªpatchåŸºäºå…¶è¯­ä¹‰å‘é‡ç”Ÿæˆç‹¬ç«‹çš„æ°´å°æ¨¡å¼ï¼Œ
        ç„¶åæ‹¼æ¥æˆå®Œæ•´çš„W_loc^S
        
        Args:
            semantic_vectors: 64ä¸ªè¯­ä¹‰å‘é‡çš„åˆ—è¡¨
            latent_size: æ½œç©ºé—´å°ºå¯¸ (4, 64, 64)
            
        Returns:
            W_loc^S: åŠ¨æ€è¯­ä¹‰å®šä½æ°´å° (torch.Tensor)
        """
        latent_len = np.prod(latent_size)  # 4 * 64 * 64 = 16384
        patch_latent_len = latent_len // self.num_patches  # 16384 // 64 = 256
        
        w_loc_s = torch.zeros(latent_len, device=self.device)
        
        print(f"Generating dynamic semantic watermark for {self.num_patches} patches...")
        
        for patch_idx, semantic_vector in enumerate(semantic_vectors):
            # ä½¿ç”¨SimHashç”Ÿæˆè¯¥patchçš„å“ˆå¸Œå€¼
            hash_value = self._compute_patch_simhash(semantic_vector, patch_idx)
            
            # åŸºäºå“ˆå¸Œå€¼ç”Ÿæˆè¯¥patchçš„æ°´å°æ¯”ç‰¹æµ
            patch_watermark_bits = self._generate_patch_watermark_bits(hash_value, patch_latent_len)
            
            # å°†è¯¥patchçš„æ°´å°å¡«å…¥å¯¹åº”ä½ç½®
            start_idx = patch_idx * patch_latent_len
            end_idx = (patch_idx + 1) * patch_latent_len
            w_loc_s[start_idx:end_idx] = torch.from_numpy(patch_watermark_bits).float().to(self.device)
        
        print("Dynamic semantic watermark generation completed.")
        return w_loc_s
    
    def generate_xor_based_semantic_watermark(self, semantic_vectors: List[torch.Tensor], latent_size: Tuple[int, int, int]) -> torch.Tensor:
        """
        XORåŸºç¡€æ¨¡å¼çš„è¯­ä¹‰å®šä½æ°´å°ç”Ÿæˆ
        
        æµç¨‹å›¾:
        è¯­ä¹‰å‘é‡ v_i â†’ è¯­ä¹‰å¯†é’¥ K_sem â†˜
                                            XOR â†’ æœ€ç»ˆå®šä½æ°´å° W_loc_final â†’ DMJS â†’ æ°´å°åŒ–å™ªå£° Z_T^w
        åŸºç¡€æ¨¡å¼ P_base â†—
        
        æ­¥éª¤ï¼š
        1. ç”Ÿæˆç¡®å®šæ€§åŸºç¡€æ¨¡å¼ P_baseï¼ˆå®Œç¾æ£‹ç›˜æ ¼ï¼‰
        2. ç”Ÿæˆè¯­ä¹‰å¯†é’¥ K_semï¼ˆåŸºäºpatchè¯­ä¹‰ï¼‰  
        3. XORæ··åˆç”Ÿæˆæœ€ç»ˆå®šä½æ°´å° W_loc_final
        4. æœ€ç»ˆåˆ†å¸ƒæ ¡æ­£ç¡®ä¿ä¸¥æ ¼0.5åˆ†å¸ƒ
        
        Args:
            semantic_vectors: 64ä¸ªè¯­ä¹‰å‘é‡çš„åˆ—è¡¨
            latent_size: æ½œç©ºé—´å°ºå¯¸ (4, 64, 64)
            
        Returns:
            W_loc_final: XORæ··åˆçš„æœ€ç»ˆå®šä½æ°´å° (torch.Tensor)
        """
        print("ğŸ”€ ç”ŸæˆXORåŸºç¡€æ¨¡å¼çš„è¯­ä¹‰å®šä½æ°´å°...")
        
        latent_len = np.prod(latent_size)  # 4 * 64 * 64 = 16384
        
        # === æ­¥éª¤1ï¼šç”Ÿæˆç¡®å®šæ€§åŸºç¡€æ¨¡å¼ P_base ===
        print("  ğŸ“ æ­¥éª¤1ï¼šç”ŸæˆåŸºç¡€æ¨¡å¼ï¼ˆé«˜é¢‘æ£‹ç›˜æ ¼ï¼‰")
        P_base = self._generate_perfect_base_pattern(latent_len)
        
        # === æ­¥éª¤2ï¼šç”Ÿæˆå†…å®¹ç›¸å…³çš„è¯­ä¹‰å¯†é’¥ K_sem ===
        print("  ğŸ”‘ æ­¥éª¤2ï¼šç”Ÿæˆè¯­ä¹‰å¯†é’¥")
        K_sem = self._generate_semantic_modulation_key(semantic_vectors, latent_len)
        
        # === æ­¥éª¤3ï¼šXORæ··åˆç”Ÿæˆæœ€ç»ˆå®šä½æ°´å° ===
        print("  ğŸ”€ æ­¥éª¤3ï¼šXORæ··åˆç”Ÿæˆæœ€ç»ˆå®šä½æ°´å°")
        W_loc_final = P_base ^ K_sem
        
        # === æ­¥éª¤4ï¼šæœ€ç»ˆåˆ†å¸ƒæ ¡æ­£ï¼ˆå…³é”®ä¿®å¤ï¼‰===
        print("  ğŸ”§ æ­¥éª¤4ï¼šæœ€ç»ˆåˆ†å¸ƒæ ¡æ­£")
        W_loc_final = self._apply_final_distribution_correction_semantic(W_loc_final, semantic_vectors)
        
        # éªŒè¯ç»Ÿè®¡ç‰¹æ€§
        ones_ratio = (W_loc_final == 1).sum() / len(W_loc_final)
        print(f"âœ… XORè¯­ä¹‰å®šä½æ°´å°ç”Ÿæˆå®Œæˆ")
        print(f"  ğŸ“Š åŸºç¡€æ¨¡å¼1çš„æ¯”ä¾‹: {(P_base == 1).sum() / len(P_base):.6f}")
        print(f"  ğŸ“Š è¯­ä¹‰å¯†é’¥1çš„æ¯”ä¾‹: {(K_sem == 1).sum() / len(K_sem):.6f}")
        print(f"  ğŸ“Š æœ€ç»ˆæ°´å°1çš„æ¯”ä¾‹: {ones_ratio:.6f} (ç›®æ ‡: 0.500000)")
        print(f"  ğŸ¯ å®Œç¾ç»Ÿè®¡ç‰¹æ€§ + è¯­ä¹‰ç»‘å®š = æœ€ä¼˜å®šä½æ°´å°")
        
        # è½¬æ¢ä¸ºtorch tensorå¹¶reshape
        w_loc_tensor = torch.from_numpy(W_loc_final).float().to(self.device)
        w_loc_tensor = w_loc_tensor.reshape(latent_size)
        
        return w_loc_tensor
    
    def _generate_perfect_base_pattern(self, total_bits: int) -> np.ndarray:
        """
        ç”Ÿæˆå®Œç¾çš„åŸºç¡€æ¨¡å¼ P_base
        
        ç‰¹æ€§ï¼š
        - ä¸¥æ ¼äº¤æ›¿çš„0-1-0-1-0-1...æ¨¡å¼
        - å®Œç¾çš„ä¼¯åŠªåˆ©(0.5)åˆ†å¸ƒï¼š0å’Œ1æ•°é‡ä¸¥æ ¼ç›¸ç­‰
        - é«˜é¢‘æ£‹ç›˜æ ¼ç»“æ„ï¼šå¯¹ä»»ä½•å¹³æ»‘/æ¨¡ç³Šæ“ä½œæœ€æ•æ„Ÿ
        - å®Œå…¨ç¡®å®šæ€§ï¼šä¸ä¾èµ–ä»»ä½•å›¾åƒå†…å®¹
        
        Args:
            total_bits: æ€»æ¯”ç‰¹æ•° (16384)
            
        Returns:
            P_base: åŸºç¡€æ¨¡å¼æ•°ç»„ (0,1,0,1,...)
        """
        # å®Œå…¨å¤ç°TAG-WMçš„å¥‡å¶æ¨¡å¼
        P_base = np.arange(total_bits) % 2
        
        # éªŒè¯å®Œç¾åˆ†å¸ƒç‰¹æ€§
        ones_count = (P_base == 1).sum()
        zeros_count = (P_base == 0).sum()
        ones_ratio = ones_count / total_bits
        
        print(f"    ğŸ“ åŸºç¡€æ¨¡å¼ç”Ÿæˆ: {total_bits}ä½")
        print(f"    ğŸ“Š 0çš„æ•°é‡: {zeros_count}, 1çš„æ•°é‡: {ones_count}")
        print(f"    ğŸ“Š 1çš„æ¯”ä¾‹: {ones_ratio:.6f} (å®Œç¾ç›®æ ‡: 0.500000)")
        print(f"    ğŸ¯ é«˜é¢‘æ£‹ç›˜æ ¼ç»“æ„: å¯¹ç¯¡æ”¹æœ€æ•æ„Ÿ")
        
        return P_base.astype(np.int32)
    
    def _generate_semantic_modulation_key(self, semantic_vectors: List[torch.Tensor], total_bits: int) -> np.ndarray:
        """
        ç”Ÿæˆè¯­ä¹‰è°ƒåˆ¶å¯†é’¥ K_sem
        
        ä¸ºæ¯ä¸ªpatchåŸºäºå…¶è¯­ä¹‰å‘é‡ç”Ÿæˆç¡®å®šæ€§çš„ä¼ªéšæœºå¯†é’¥ï¼Œ
        ç„¶åæ‹¼æ¥æˆå®Œæ•´çš„K_sem
        **æ–°å¢åˆ†å¸ƒæ ¡æ­£æœºåˆ¶ï¼Œç¡®ä¿ä¸¥æ ¼0.5åˆ†å¸ƒ**
        
        Args:
            semantic_vectors: 64ä¸ªè¯­ä¹‰å‘é‡çš„åˆ—è¡¨
            total_bits: æ€»æ¯”ç‰¹æ•° (16384)
            
        Returns:
            K_sem: è¯­ä¹‰è°ƒåˆ¶å¯†é’¥ (ä¼ªéšæœºï¼Œä½†ç¡®å®šæ€§ï¼Œä¸¥æ ¼0.5åˆ†å¸ƒ)
        """
        num_patches = len(semantic_vectors)  # 64
        bits_per_patch = total_bits // num_patches  # 256
        
        K_sem = np.zeros(total_bits, dtype=np.int32)
        
        print(f"    ğŸ”‘ è¯­ä¹‰å¯†é’¥ç”Ÿæˆ: {num_patches}ä¸ªpatch, æ¯ä¸ª{bits_per_patch}ä½")
        
        for patch_idx, semantic_vector in enumerate(semantic_vectors):
            # ä½¿ç”¨å¢å¼ºçš„SimHashç”Ÿæˆè¯¥patchçš„ç§å­
            patch_seed = self._compute_enhanced_patch_seed(semantic_vector, patch_idx)
            
            # åŸºäºç§å­ç”Ÿæˆè¯¥patchçš„ä¼ªéšæœºå¯†é’¥æ¯”ç‰¹
            patch_key_bits = self._generate_patch_key_bits(patch_seed, bits_per_patch)
            
            # å¡«å…¥å¯¹åº”ä½ç½®
            start_idx = patch_idx * bits_per_patch
            end_idx = start_idx + bits_per_patch
            K_sem[start_idx:end_idx] = patch_key_bits
        
        # å¤„ç†ä½™æ•°ä½ï¼ˆå¦‚æœæœ‰ï¼‰
        remaining_bits = total_bits % num_patches
        if remaining_bits > 0:
            # ä½¿ç”¨æœ€åä¸€ä¸ªpatchçš„ç§å­ç”Ÿæˆä½™æ•°ä½
            last_semantic_vector = semantic_vectors[-1]
            last_seed = self._compute_enhanced_patch_seed(last_semantic_vector, num_patches)
            remaining_key_bits = self._generate_patch_key_bits(last_seed, remaining_bits)
            K_sem[-remaining_bits:] = remaining_key_bits
        
        # â­ æ–°å¢ï¼šåˆ†å¸ƒæ ¡æ­£æœºåˆ¶ â­
        K_sem = self._apply_semantic_distribution_correction(K_sem, semantic_vectors)
        
        # éªŒè¯ä¼ªéšæœºæ€§
        ones_ratio = (K_sem == 1).sum() / total_bits
        print(f"    ğŸ“Š è¯­ä¹‰å¯†é’¥ç»Ÿè®¡: 1çš„æ¯”ä¾‹ {ones_ratio:.6f} (æ ¡æ­£åï¼Œä¸¥æ ¼0.5)")
        print(f"    ğŸ” æ¯ä¸ªpatchç‹¬ç«‹ç»‘å®š: è¯­ä¹‰å†…å®¹ â†’ ç¡®å®šæ€§ç§å­ â†’ ä¼ªéšæœºå¯†é’¥")
        
        return K_sem
    
    def _apply_semantic_distribution_correction(self, K_sem: np.ndarray, semantic_vectors: List[torch.Tensor]) -> np.ndarray:
        """
        åº”ç”¨è¯­ä¹‰åˆ†å¸ƒæ ¡æ­£æœºåˆ¶ï¼Œç¡®ä¿K_semä¸¥æ ¼æ»¡è¶³0.5åˆ†å¸ƒ
        
        ç­–ç•¥ï¼š
        1. è®¡ç®—å½“å‰1çš„æ•°é‡å’Œç›®æ ‡æ•°é‡çš„å·®å€¼
        2. åŸºäºè¯­ä¹‰å‘é‡ç‰¹å¾ç”Ÿæˆç¡®å®šæ€§çš„ä½ç½®åºåˆ—
        3. æŒ‰åºåˆ—ç¿»è½¬å¯¹åº”ä½ç½®çš„æ¯”ç‰¹ï¼Œç›´åˆ°è¾¾åˆ°ä¸¥æ ¼0.5åˆ†å¸ƒ
        
        Args:
            K_sem: åŸå§‹è¯­ä¹‰å¯†é’¥
            semantic_vectors: è¯­ä¹‰å‘é‡åˆ—è¡¨ï¼ˆç”¨äºç”Ÿæˆç¡®å®šæ€§æ ¡æ­£åºåˆ—ï¼‰
            
        Returns:
            æ ¡æ­£åçš„è¯­ä¹‰å¯†é’¥ï¼ˆä¸¥æ ¼0.5åˆ†å¸ƒï¼‰
        """
        total_bits = len(K_sem)
        target_ones = total_bits // 2  # ä¸¥æ ¼çš„ä¸€åŠ
        current_ones = (K_sem == 1).sum()
        
        print(f"    ğŸ”§ åˆ†å¸ƒæ ¡æ­£: å½“å‰1çš„æ•°é‡={current_ones}, ç›®æ ‡={target_ones}")
        
        if current_ones == target_ones:
            print(f"    âœ… å·²æ˜¯å®Œç¾åˆ†å¸ƒï¼Œæ— éœ€æ ¡æ­£")
            return K_sem
        
        # åˆ›å»ºå‰¯æœ¬è¿›è¡Œæ ¡æ­£
        K_sem_corrected = K_sem.copy()
        
        # åŸºäºè¯­ä¹‰å‘é‡ç”Ÿæˆç¡®å®šæ€§çš„æ ¡æ­£ä½ç½®åºåˆ—
        semantic_fingerprint = self._compute_semantic_fingerprint(semantic_vectors)
        correction_seed = int(hashlib.md5(f"{semantic_fingerprint}_correction".encode()).hexdigest()[:8], 16)
        correction_seed = correction_seed & 0x7FFFFFFF
        
        rng = np.random.RandomState(correction_seed)
        position_sequence = rng.permutation(total_bits)
        
        if current_ones > target_ones:
            # éœ€è¦å°†ä¸€äº›1æ”¹ä¸º0
            excess_ones = current_ones - target_ones
            ones_positions = np.where(K_sem_corrected == 1)[0]
            # æŒ‰ç¡®å®šæ€§åºåˆ—é€‰æ‹©è¦ç¿»è½¬çš„ä½ç½®
            positions_to_flip = []
            for pos in position_sequence:
                if pos in ones_positions and len(positions_to_flip) < excess_ones:
                    positions_to_flip.append(pos)
            K_sem_corrected[positions_to_flip] = 0
            print(f"    ğŸ”„ ç¿»è½¬{len(positions_to_flip)}ä¸ª1â†’0")
            
        elif current_ones < target_ones:
            # éœ€è¦å°†ä¸€äº›0æ”¹ä¸º1
            deficit_ones = target_ones - current_ones
            zeros_positions = np.where(K_sem_corrected == 0)[0]
            # æŒ‰ç¡®å®šæ€§åºåˆ—é€‰æ‹©è¦ç¿»è½¬çš„ä½ç½®
            positions_to_flip = []
            for pos in position_sequence:
                if pos in zeros_positions and len(positions_to_flip) < deficit_ones:
                    positions_to_flip.append(pos)
            K_sem_corrected[positions_to_flip] = 1
            print(f"    ğŸ”„ ç¿»è½¬{len(positions_to_flip)}ä¸ª0â†’1")
        
        # éªŒè¯æ ¡æ­£ç»“æœ
        final_ones = (K_sem_corrected == 1).sum()
        final_ratio = final_ones / total_bits
        print(f"    âœ… æ ¡æ­£å®Œæˆ: 1çš„æ•°é‡={final_ones}, æ¯”ä¾‹={final_ratio:.6f}")
        
        return K_sem_corrected
    
    def _apply_final_distribution_correction_semantic(self, W_loc_final: np.ndarray, semantic_vectors: List[torch.Tensor]) -> np.ndarray:
        """
        åº”ç”¨åŸºäºè¯­ä¹‰çš„æœ€ç»ˆåˆ†å¸ƒæ ¡æ­£ï¼Œç¡®ä¿XORåçš„ç»“æœä¸¥æ ¼æ»¡è¶³0.5åˆ†å¸ƒ
        
        Args:
            W_loc_final: XORåçš„åŸå§‹æœ€ç»ˆæ°´å°
            semantic_vectors: è¯­ä¹‰å‘é‡åˆ—è¡¨ï¼ˆç”¨äºç”Ÿæˆç¡®å®šæ€§æ ¡æ­£åºåˆ—ï¼‰
            
        Returns:
            æ ¡æ­£åçš„æœ€ç»ˆæ°´å°ï¼ˆä¸¥æ ¼0.5åˆ†å¸ƒï¼‰
        """
        total_bits = len(W_loc_final)
        target_ones = total_bits // 2  # ä¸¥æ ¼çš„ä¸€åŠ
        current_ones = (W_loc_final == 1).sum()
        
        print(f"    ğŸ”§ æœ€ç»ˆæ ¡æ­£: å½“å‰1çš„æ•°é‡={current_ones}, ç›®æ ‡={target_ones}")
        
        if current_ones == target_ones:
            print(f"    âœ… å·²æ˜¯å®Œç¾åˆ†å¸ƒï¼Œæ— éœ€æ ¡æ­£")
            return W_loc_final
        
        # åˆ›å»ºå‰¯æœ¬è¿›è¡Œæ ¡æ­£
        W_loc_corrected = W_loc_final.copy()
        
        # åŸºäºè¯­ä¹‰å‘é‡ç”Ÿæˆç¡®å®šæ€§çš„æ ¡æ­£ä½ç½®åºåˆ—
        semantic_fingerprint = self._compute_semantic_fingerprint(semantic_vectors)
        correction_seed = int(hashlib.md5(f"{semantic_fingerprint}_final_correction".encode()).hexdigest()[:8], 16)
        correction_seed = correction_seed & 0x7FFFFFFF
        
        rng = np.random.RandomState(correction_seed)
        position_sequence = rng.permutation(total_bits)
        
        if current_ones > target_ones:
            # éœ€è¦å°†ä¸€äº›1æ”¹ä¸º0
            excess_ones = current_ones - target_ones
            ones_positions = np.where(W_loc_corrected == 1)[0]
            # æŒ‰ç¡®å®šæ€§åºåˆ—é€‰æ‹©è¦ç¿»è½¬çš„ä½ç½®
            positions_to_flip = []
            for pos in position_sequence:
                if pos in ones_positions and len(positions_to_flip) < excess_ones:
                    positions_to_flip.append(pos)
            W_loc_corrected[positions_to_flip] = 0
            print(f"    ğŸ”„ ç¿»è½¬{len(positions_to_flip)}ä¸ª1â†’0")
            
        elif current_ones < target_ones:
            # éœ€è¦å°†ä¸€äº›0æ”¹ä¸º1
            deficit_ones = target_ones - current_ones
            zeros_positions = np.where(W_loc_corrected == 0)[0]
            # æŒ‰ç¡®å®šæ€§åºåˆ—é€‰æ‹©è¦ç¿»è½¬çš„ä½ç½®
            positions_to_flip = []
            for pos in position_sequence:
                if pos in zeros_positions and len(positions_to_flip) < deficit_ones:
                    positions_to_flip.append(pos)
            W_loc_corrected[positions_to_flip] = 1
            print(f"    ğŸ”„ ç¿»è½¬{len(positions_to_flip)}ä¸ª0â†’1")
        
        # éªŒè¯æ ¡æ­£ç»“æœ
        final_ones = (W_loc_corrected == 1).sum()
        final_ratio = final_ones / total_bits
        print(f"    âœ… æœ€ç»ˆæ ¡æ­£å®Œæˆ: 1çš„æ•°é‡={final_ones}, æ¯”ä¾‹={final_ratio:.6f}")
        
        return W_loc_corrected
    
    def _compute_semantic_fingerprint(self, semantic_vectors: List[torch.Tensor]) -> str:
        """
        è®¡ç®—è¯­ä¹‰å‘é‡çš„æŒ‡çº¹ï¼Œç”¨äºç”Ÿæˆç¡®å®šæ€§çš„æ ¡æ­£ç§å­
        
        Args:
            semantic_vectors: è¯­ä¹‰å‘é‡åˆ—è¡¨
            
        Returns:
            è¯­ä¹‰æŒ‡çº¹å­—ç¬¦ä¸²
        """
        # è®¡ç®—æ‰€æœ‰è¯­ä¹‰å‘é‡çš„ç»Ÿè®¡ç‰¹å¾
        all_vectors = torch.stack(semantic_vectors)  # (64, 768)
        
        # æå–å…³é”®ç»Ÿè®¡ç‰¹å¾
        mean_val = float(all_vectors.mean())
        std_val = float(all_vectors.std())
        max_val = float(all_vectors.max())
        min_val = float(all_vectors.min())
        
        # ç”ŸæˆæŒ‡çº¹
        fingerprint = f"{mean_val:.6f}_{std_val:.6f}_{max_val:.6f}_{min_val:.6f}"
        
        return fingerprint
    
    def _compute_enhanced_patch_seed(self, semantic_vector: torch.Tensor, patch_idx: int) -> int:
        """
        è®¡ç®—å¢å¼ºçš„patchç§å­
        
        ç»“åˆè¯­ä¹‰å‘é‡ã€patchä½ç½®å’Œå…¨å±€saltç”Ÿæˆé«˜è´¨é‡çš„ç§å­
        
        Args:
            semantic_vector: è¯¥patchçš„è¯­ä¹‰å‘é‡ (768ç»´)
            patch_idx: patchç´¢å¼• (0-63)
            
        Returns:
            å¢å¼ºçš„ç§å­å€¼
        """
        # ä½¿ç”¨ä¼˜åŒ–çš„SimHash
        from simhash_utils import simhash_single_patch
        
        base_hash = simhash_single_patch(
            semantic_vector,
            num_bits=self.simhash_bits,
            seed=42 + patch_idx
        )
        
        # å¤šå±‚å“ˆå¸Œå¢å¼º
        # ç¬¬ä¸€å±‚ï¼šç»“åˆpatchç´¢å¼•
        layer1_input = f"{base_hash}_{patch_idx}_{self.encrypt_random_seed}"
        layer1_hash = int(hashlib.md5(layer1_input.encode()).hexdigest()[:8], 16)
        
        # ç¬¬äºŒå±‚ï¼šç»“åˆè¯­ä¹‰å‘é‡çš„ç»Ÿè®¡ç‰¹å¾
        semantic_stats = {
            'mean': float(semantic_vector.mean()),
            'std': float(semantic_vector.std()),
            'max': float(semantic_vector.max()),
            'min': float(semantic_vector.min())
        }
        layer2_input = f"{layer1_hash}_{semantic_stats['mean']:.6f}_{semantic_stats['std']:.6f}"
        layer2_hash = int(hashlib.sha256(layer2_input.encode()).hexdigest()[:8], 16)
        
        # æœ€ç»ˆç§å­
        final_seed = layer2_hash & 0x7FFFFFFF  # ç¡®ä¿æ­£æ•°
        
        return final_seed
    
    def _generate_patch_key_bits(self, seed: int, length: int) -> np.ndarray:
        """
        åŸºäºç§å­ç”Ÿæˆé«˜è´¨é‡çš„ä¼ªéšæœºå¯†é’¥æ¯”ç‰¹
        
        Args:
            seed: ç¡®å®šæ€§ç§å­
            length: éœ€è¦ç”Ÿæˆçš„æ¯”ç‰¹æ•°é‡
            
        Returns:
            ä¼ªéšæœºæ¯”ç‰¹æ•°ç»„ (0/1)
        """
        # ä½¿ç”¨numpyçš„Mersenne Twisterç”Ÿæˆå™¨ï¼Œç¡®ä¿é«˜è´¨é‡ä¼ªéšæœºæ€§
        rng = np.random.RandomState(seed)
        key_bits = rng.randint(0, 2, size=length, dtype=np.int32)
        
        return key_bits
    
    def _compute_patch_simhash(self, semantic_vector: torch.Tensor, patch_idx: int) -> int:
        """
        ä¸ºå•ä¸ªpatchè®¡ç®—SimHashå€¼
        
        Args:
            semantic_vector: è¯¥patchçš„è¯­ä¹‰å‘é‡ (768ç»´)
            patch_idx: patchç´¢å¼• (0-63)
            
        Returns:
            æ•´æ•°å“ˆå¸Œå€¼ï¼Œç”¨ä½œPRNGç§å­
        """
        # å¯¼å…¥æœ¬åœ°çš„simhashå‡½æ•°
        from simhash_utils import simhash_single_patch
        
        # ä½¿ç”¨ä¼˜åŒ–çš„å•patch SimHashå‡½æ•°
        base_hash = simhash_single_patch(
            semantic_vector, 
            num_bits=self.simhash_bits,
            seed=42 + patch_idx  # ä¸ºæ¯ä¸ªpatchä½¿ç”¨ä¸åŒç§å­
        )
        
        # ç»“åˆpatchç´¢å¼•å’Œå…¨å±€saltç”Ÿæˆæœ€ç»ˆç§å­
        # å¤ç”¨TAG-WMçš„ç¡®å®šæ€§éšæœºæ•°ç”Ÿæˆæœºåˆ¶
        combined_seed = f"{base_hash}_{patch_idx}_{self.encrypt_random_seed}"
        
        # ä½¿ç”¨å“ˆå¸Œå‡½æ•°ç”Ÿæˆæœ€ç»ˆçš„æ•´æ•°ç§å­
        final_seed = int(hashlib.md5(combined_seed.encode()).hexdigest()[:8], 16)
        
        return final_seed
    
    def _generate_patch_watermark_bits(self, seed: int, length: int) -> np.ndarray:
        """
        åŸºäºç§å­ç”Ÿæˆç¡®å®šæ€§çš„æ°´å°æ¯”ç‰¹æµ
        
        Args:
            seed: SimHashç”Ÿæˆçš„ç§å­
            length: éœ€è¦ç”Ÿæˆçš„æ¯”ç‰¹æ•°é‡
            
        Returns:
            äºŒè¿›åˆ¶æ¯”ç‰¹æ•°ç»„ (0/1)
        """
        # ä½¿ç”¨numpyçš„éšæœºæ•°ç”Ÿæˆå™¨ï¼Œç¡®ä¿ç¡®å®šæ€§
        rng = np.random.RandomState(seed)
        watermark_bits = rng.randint(0, 2, size=length, dtype=np.uint8)
        return watermark_bits
    
    def save_semantic_map(self, semantic_vectors: List[torch.Tensor], identifier: str):
        """
        ä¿å­˜åŸºå‡†çœŸå®è¯­ä¹‰åœ°å›¾åˆ°æœ¬åœ°æ–‡ä»¶
        
        Args:
            semantic_vectors: 64ä¸ªè¯­ä¹‰å‘é‡
            identifier: å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆå¦‚promptçš„hashï¼‰
        """
        # å°†è¯­ä¹‰å‘é‡åˆ—è¡¨è½¬æ¢ä¸ºå¼ é‡
        semantic_map = torch.stack(semantic_vectors)  # Shape: (64, 768)
        
        # ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
        save_path = os.path.join(self.semantic_maps_dir, f"semantic_map_{identifier}.pt")
        torch.save(semantic_map, save_path)
        
        print(f"Semantic map saved to: {save_path}")
        return save_path
    
    def load_semantic_map(self, identifier: str) -> Optional[List[torch.Tensor]]:
        """
        ä»æœ¬åœ°æ–‡ä»¶åŠ è½½åŸºå‡†è¯­ä¹‰åœ°å›¾
        
        Args:
            identifier: å”¯ä¸€æ ‡è¯†ç¬¦
            
        Returns:
            è¯­ä¹‰å‘é‡åˆ—è¡¨ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å›None
        """
        load_path = os.path.join(self.semantic_maps_dir, f"semantic_map_{identifier}.pt")
        
        if not os.path.exists(load_path):
            return None
        
        try:
            semantic_map = torch.load(load_path, map_location=self.device)  # Shape: (64, 768)
            semantic_vectors = [semantic_map[i] for i in range(semantic_map.shape[0])]
            print(f"Semantic map loaded from: {load_path}")
            return semantic_vectors
        except Exception as e:
            print(f"Error loading semantic map: {e}")
            return None
    
    def text_to_bits(self, text):
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ¯”ç‰¹åºåˆ—"""
        # å°†æ–‡æœ¬è½¬æ¢ä¸ºå­—èŠ‚ï¼Œç„¶åè½¬æ¢ä¸ºæ¯”ç‰¹
        text_bytes = text.encode('utf-8')
        bits = []
        for byte in text_bytes:
            for i in range(8):
                bits.append((byte >> (7-i)) & 1)
        return torch.tensor(bits, dtype=torch.float32, device=self.device)
    
    def embedding_seal_loc(self, prompt: str, wm: torch.Tensor, latent_size: Tuple[int, int, int], pipe=None) -> torch.Tensor:
        """
        SEAL-LOCå®Œæ•´åµŒå…¥æµç¨‹
        
        é›†æˆå…­ä¸ªé˜¶æ®µï¼š
        1. ä»£ç†ç”Ÿæˆä¸åˆå§‹è¡¨ç¤º
        2. é€è¡¥ä¸è¯­ä¹‰ç‰¹å¾æå–  
        3. åŠ¨æ€è¯­ä¹‰å®šä½æ°´å°ç”Ÿæˆ
        4. ç‰ˆæƒæ°´å°ç”Ÿæˆï¼ˆå¤ç”¨TAG-WMï¼‰
        5. åŒæ°´å°è”åˆé‡‡æ ·ï¼ˆDMJSï¼‰
        6. æ‰©æ•£ç”Ÿæˆä¸è§£ç 
        
        Args:
            prompt: ç”¨æˆ·æ–‡æœ¬æç¤ºè¯
            wm: ç‰ˆæƒæ°´å°æ¯”ç‰¹ä¸² (256ä½)
            latent_size: æ½œç©ºé—´å°ºå¯¸ (4, 64, 64)
            pipe: æ‰©æ•£æ¨¡å‹ç®¡çº¿ (å¯é€‰)
            
        Returns:
            latent_noise: æ°´å°åŒ–çš„åˆå§‹å™ªå£°
        """
        print("=== SEAL-LOC Watermark Embedding Pipeline ===")
        
        # é˜¶æ®µä¸€ï¼šç”Ÿæˆä»£ç†å›¾åƒ
        print("Stage 1: Proxy image generation...")
        if pipe is not None:
            proxy_image = self.generate_proxy_image(prompt, pipe)
        else:
            proxy_image = self.generate_proxy_image(prompt)
        
        # é˜¶æ®µäºŒï¼šé€è¡¥ä¸è¯­ä¹‰æå–
        print("Stage 2: Patch-wise semantic extraction...")
        semantic_vectors = self.extract_patch_semantics(proxy_image, latent_size)
        
        # ä¿å­˜åŸºå‡†è¯­ä¹‰åœ°å›¾
        prompt_hash = hashlib.md5(prompt.encode()).hexdigest()[:16]
        self.save_semantic_map(semantic_vectors, prompt_hash)
        
        # é˜¶æ®µä¸‰ï¼šXORåŸºç¡€æ¨¡å¼çš„è¯­ä¹‰å®šä½æ°´å°ç”Ÿæˆ
        print("Stage 3: XOR-based semantic watermark generation...")
        w_loc_s = self.generate_xor_based_semantic_watermark(semantic_vectors, latent_size)
        
        # é˜¶æ®µå››ï¼šç‰ˆæƒæ°´å°ç”Ÿæˆï¼ˆå¤ç”¨TAG-WMé€»è¾‘ï¼‰
        print("Stage 4: Copyright watermark generation...")
        latent_len = np.prod(latent_size)
        tlt_dummy = torch.zeros(latent_len, device=self.device)  # å ä½ç¬¦ï¼Œå°†è¢«w_loc_sæ›¿ä»£
        w_cop = self._generate_copyright_watermark(wm, latent_len)
        
        # é˜¶æ®µäº”ï¼šåŒæ°´å°è”åˆé‡‡æ ·ï¼ˆDMJSï¼‰
        print("Stage 5: Dual watermark joint sampling (DMJS)...")
        latent_noise, wm_repeat = self.embedding_wm_tlt(w_cop, w_loc_s, latent_size)
        
        print("=== SEAL-LOC Embedding Completed ===")
        return latent_noise
    
    def _generate_copyright_watermark(self, wm: torch.Tensor, latent_len: int) -> torch.Tensor:
        """
        ç”Ÿæˆç‰ˆæƒæ°´å°ï¼ˆå¤ç”¨TAG-WMçš„é€»è¾‘ï¼‰
        
        Args:
            wm: åŸå§‹æ°´å°æ¯”ç‰¹ä¸²
            latent_len: æ½œç©ºé—´æ€»é•¿åº¦
            
        Returns:
            æ‰©å±•å¹¶åŠ å¯†åçš„ç‰ˆæƒæ°´å°
        """
        # é‡å¤å±•å¼€æ°´å°ä»¥è¦†ç›–æ½œç©ºé—´
        wm_len = wm.shape[0]
        wm_times = int(latent_len // wm_len)
        remain_wm_len = latent_len % wm_len
        wm_repeat = torch.concat([wm.repeat(wm_times), wm[:remain_wm_len]], dim=0)
        
        # æµåŠ å¯†ï¼ˆå¯é€‰ï¼‰- ç¡®ä¿è¾“å…¥æ˜¯æ•´æ•°ç±»å‹
        wm_repeat_int = wm_repeat.cpu().numpy().astype(np.uint8)
        wm_repeat_encrypt = self.stream_key_encrypt(wm_repeat_int)
        
        return torch.from_numpy(wm_repeat_encrypt).float().to(self.device)


if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # åˆå§‹åŒ–SEAL-LOCåµŒå…¥å™¨
    seal_loc = SEALLOCEmbedder(device=device)
    
    print("SEAL-LOC Embedder initialized successfully!")
    print(f"Number of patches: {seal_loc.num_patches}")
    print(f"Semantic vector dimension: {seal_loc.semantic_vector_dim}") 